# æ•°å­—äººå®æ—¶è¯­éŸ³äº¤äº’æ–¹æ¡ˆ - å¿«é€Ÿé›†æˆæŒ‡å—

## ğŸš€ æ–¹æ¡ˆä¸€ï¼šåŸºäºOpenAvatarChatçš„å®Œæ•´é›†æˆï¼ˆæ¨èï¼‰

### æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Android App (Kotlin/Compose)       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Live2Dæ•°å­—äººæ¸²æŸ“                 â”‚  â”‚
â”‚  â”‚  + è¯­éŸ³é‡‡é›†/æ’­æ”¾                  â”‚  â”‚
â”‚  â”‚  + WebRTCå®¢æˆ·ç«¯                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†• WebRTC/WebSocket
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Node.jsåç«¯æœåŠ¡ (ç°æœ‰é¡¹ç›®)            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  WebSocketç½‘å…³                    â”‚  â”‚
â”‚  â”‚  + ä¼šè¯ç®¡ç†                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†• gRPC/HTTP
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OpenAvatarChatæœåŠ¡ (Python)            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  RTCæœåŠ¡ç«¯                        â”‚  â”‚
â”‚  â”‚  + VAD (è¯­éŸ³æ´»åŠ¨æ£€æµ‹)             â”‚  â”‚
â”‚  â”‚  + ASR (FunASR)                  â”‚  â”‚
â”‚  â”‚  + LLM (DeepSeek/æ‚¨çš„æœåŠ¡)        â”‚  â”‚
â”‚  â”‚  + TTS (IndexTTS2/é˜¿é‡Œäº‘)         â”‚  â”‚
â”‚  â”‚  + æ‰“æ–­æ£€æµ‹ä¸å¤„ç†                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ç¬¬ä¸€æ­¥ï¼šéƒ¨ç½²OpenAvatarChatæœåŠ¡

```bash
# 1. å…‹éš†é¡¹ç›®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
git clone https://github.com/HumanAIGC-Engineering/OpenAvatarChat.git
cd OpenAvatarChat

# 2. åˆ›å»ºPythonè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 4. é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘.envæ–‡ä»¶ï¼Œé…ç½®ASR/TTS/LLMæœåŠ¡
```

### ç¬¬äºŒæ­¥ï¼šé…ç½®ASRæœåŠ¡ï¼ˆFunASRï¼‰

```bash
# å®‰è£…FunASR
pip install funasr

# æˆ–è€…ä½¿ç”¨Dockeréƒ¨ç½²
docker pull registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-cpu-0.4.7
```

```python
# funasr_config.py
FUNASR_CONFIG = {
    "model_dir": "./models/funasr",
    "vad_model": "fsmn-vad",
    "asr_model": "paraformer-zh",
    "sample_rate": 16000,
    "vad_threshold": 0.5,  # VADé˜ˆå€¼ï¼Œç”¨äºæ‰“æ–­æ£€æµ‹
}
```

### ç¬¬ä¸‰æ­¥ï¼šé…ç½®TTSæœåŠ¡

```python
# tts_config.py
# ä½¿ç”¨æ‚¨ç°æœ‰çš„IndexTTS2æˆ–é˜¿é‡Œäº‘TTS
TTS_CONFIG = {
    "provider": "aliyun",  # æˆ– "index-tts2"
    "voice": "siqi",
    "sample_rate": 16000,
    "format": "pcm",  # å®æ—¶æµå¼è¾“å‡º
}
```

### ç¬¬å››æ­¥ï¼šé…ç½®LLMæœåŠ¡

```python
# llm_config.py
# ä½¿ç”¨æ‚¨ç°æœ‰çš„DeepSeekæœåŠ¡
LLM_CONFIG = {
    "provider": "deepseek",
    "api_key": os.getenv("DEEPSEEK_API_KEY"),
    "base_url": "https://api.deepseek.com/v1",
    "model": "deepseek-chat",
    "temperature": 0.7,
    "persona": "ä¸“ä¸šé¢è¯•å®˜ï¼Œ15å¹´é¢è¯•ç»éªŒ",  # æ•°å­—äººè®¾
}
```

### ç¬¬äº”æ­¥ï¼šå®ç°æ‰“æ–­æœºåˆ¶

```python
# interruption_handler.py
import asyncio
from typing import Optional

class InterruptionHandler:
    def __init__(self):
        self.is_speaking = False
        self.current_tts_task: Optional[asyncio.Task] = None
        
    async def handle_user_speech(self, audio_data: bytes):
        """æ£€æµ‹åˆ°ç”¨æˆ·è¯­éŸ³æ—¶çš„å¤„ç†"""
        if self.is_speaking:
            # æ‰“æ–­å½“å‰TTSè¾“å‡º
            await self.interrupt_speech()
            
    async def interrupt_speech(self):
        """æ‰“æ–­æ•°å­—äººè¯´è¯"""
        if self.current_tts_task:
            self.current_tts_task.cancel()
            self.is_speaking = False
            # åœæ­¢éŸ³é¢‘æ’­æ”¾
            await self.stop_audio_playback()
            
    async def start_speech(self, text: str):
        """å¼€å§‹æ•°å­—äººè¯´è¯"""
        self.is_speaking = True
        # ç”ŸæˆTTSéŸ³é¢‘
        self.current_tts_task = asyncio.create_task(
            self.generate_and_stream_tts(text)
        )
```

### ç¬¬å…­æ­¥ï¼šAndroidç«¯é›†æˆWebRTC

```kotlin
// WebRTCManager.kt
class WebRTCManager(private val context: Context) {
    private var peerConnection: PeerConnection? = null
    private var audioTrack: AudioTrack? = null
    private val signalingChannel = SignalingChannel()
    
    suspend fun initialize() {
        // åˆå§‹åŒ–PeerConnection
        val rtcConfig = PeerConnection.RTCConfiguration(
            listOf(
                PeerConnection.IceServer.builder("stun:stun.l.google.com:19302").createIceServer()
            )
        )
        
        peerConnection = PeerConnectionFactory.createPeerConnection(rtcConfig, object : PeerConnectionObserver() {
            override fun onIceCandidate(event: IceCandidate?) {
                // å‘é€ICEå€™é€‰åˆ°æœåŠ¡å™¨
                signalingChannel.sendIceCandidate(event)
            }
            
            override fun onTrack(rtcTrackEvent: RtpTransceiver?) {
                // æ¥æ”¶æœåŠ¡å™¨éŸ³é¢‘æµ
                if (rtcTrackEvent?.track is AudioTrack) {
                    handleRemoteAudio(rtcTrackEvent.track as AudioTrack)
                }
            }
        })
        
        // æ·»åŠ æœ¬åœ°éŸ³é¢‘è½¨é“
        val audioSource = PeerConnectionFactory.createAudioSource(MediaConstraints())
        audioTrack = PeerConnectionFactory.createAudioTrack("audio_track", audioSource)
        peerConnection?.addTrack(audioTrack)
    }
    
    private fun handleRemoteAudio(track: AudioTrack) {
        // æ’­æ”¾æ•°å­—äººè¯­éŸ³ï¼Œé©±åŠ¨Live2D
        track.setSink { audioBuffer ->
            // åˆ†æéŸ³é¢‘é©±åŠ¨Live2Då˜´å‹
            driveLive2DWithAudio(audioBuffer)
        }
    }
    
    fun sendAudioData(audioData: ByteArray) {
        // å‘é€ç”¨æˆ·è¯­éŸ³åˆ°æœåŠ¡å™¨
        audioTrack?.setEnabled(true)
        // å°†éŸ³é¢‘æ•°æ®å‘é€åˆ°RTCé€šé“
    }
}
```

---

## ğŸ¯ æ–¹æ¡ˆäºŒï¼šåŸºäºDUIX.ai SDKçš„å¿«é€Ÿé›†æˆ

### ç¬¬ä¸€æ­¥ï¼šè·å–SDK

```bash
# ä»GitHubè·å–Android SDK
git clone https://github.com/duix-cloud/duix-cloud-sdk.git
cd duix-cloud-sdk/android
```

### ç¬¬äºŒæ­¥ï¼šé›†æˆåˆ°Androidé¡¹ç›®

```kotlin
// build.gradle.kts (Module: app)
dependencies {
    // DUIX SDK
    implementation("com.duix:duix-android-sdk:latest")
    
    // å…¶ä»–ä¾èµ–...
}

// AndroidManifest.xml
<uses-permission android:name="android.permission.RECORD_AUDIO" />
<uses-permission android:name="android.permission.INTERNET" />
```

### ç¬¬ä¸‰æ­¥ï¼šåˆå§‹åŒ–SDK

```kotlin
// DigitalHumanManager.kt
class DigitalHumanManager(private val context: Context) {
    private var duixClient: DuixClient? = null
    
    suspend fun initialize() {
        duixClient = DuixClient.Builder(context)
            .setApiKey("your-api-key")
            .setApiSecret("your-api-secret")
            .setAvatarId("your-avatar-id")
            .setPersona("ä¸“ä¸šé¢è¯•å®˜ï¼Œ15å¹´é¢è¯•ç»éªŒ")
            .enableInterruption(true)  // å¯ç”¨æ‰“æ–­æœºåˆ¶
            .setOnAudioReceived { audioData ->
                // æ¥æ”¶æ•°å­—äººè¯­éŸ³ï¼Œé©±åŠ¨Live2D
                driveLive2DWithAudio(audioData)
            }
            .setOnTextReceived { text ->
                // æ¥æ”¶ç”Ÿæˆçš„æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰
                updateSubtitle(text)
            }
            .build()
            
        duixClient?.connect()
    }
    
    fun sendUserVoice(audioData: ByteArray) {
        duixClient?.sendAudio(audioData)
    }
    
    fun stop() {
        duixClient?.disconnect()
    }
}
```

---

## ğŸ”§ æ–¹æ¡ˆä¸‰ï¼šåŸºäºç°æœ‰æ¶æ„çš„å¢å¼ºï¼ˆæ¸è¿›å¼é›†æˆï¼‰

### å½“å‰æ¶æ„åˆ†æ

æ‚¨çš„é¡¹ç›®å·²æœ‰ï¼š
- âœ… TTSæœåŠ¡ï¼ˆIndexTTS2 + é˜¿é‡Œäº‘TTSï¼‰
- âœ… LLMæœåŠ¡ï¼ˆDeepSeekï¼‰
- âœ… WebSocketé€šä¿¡
- âœ… Live2Dæ•°å­—äººæ¸²æŸ“

### éœ€è¦å¢å¼ºçš„éƒ¨åˆ†

1. **å®æ—¶ASRæœåŠ¡**
   ```bash
   # éƒ¨ç½²FunASRæœåŠ¡
   docker run -d -p 10095:10095 \
     registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-cpu-0.4.7
   ```

2. **RTCé€šä¿¡é€šé“**
   ```typescript
   // backend-api/src/services/rtc.service.ts
   import { Server as SocketIOServer } from 'socket.io';
   import { RTCPeerConnection, RTCSessionDescription } from 'wrtc';
   
   export class RTCService {
     private io: SocketIOServer;
     
     setupRTCChannels() {
       this.io.on('connection', (socket) => {
         socket.on('offer', async (offer: RTCSessionDescriptionInit) => {
           // å¤„ç†WebRTC offer
           const pc = new RTCPeerConnection();
           // å»ºç«‹RTCè¿æ¥
         });
       });
     }
   }
   ```

3. **VADè¯­éŸ³æ´»åŠ¨æ£€æµ‹**
   ```typescript
   // backend-api/src/services/vad.service.ts
   import { VAD } from '@ricky0123/vad-web';
   
   export class VADService {
     private vad: VAD;
     
     async initialize() {
       this.vad = await VAD.new({
         workletURL: '/vad.worklet.bundle.min.js',
         modelURL: '/silero_vad.onnx',
         onSpeechStart: () => {
           // æ£€æµ‹åˆ°ç”¨æˆ·å¼€å§‹è¯´è¯
           this.handleSpeechStart();
         },
         onSpeechEnd: () => {
           // æ£€æµ‹åˆ°ç”¨æˆ·åœæ­¢è¯´è¯
           this.handleSpeechEnd();
         }
       });
     }
     
     async processAudio(audioData: Float32Array) {
       await this.vad.processBuffer(audioData);
     }
   }
   ```

4. **æ‰“æ–­æœºåˆ¶å®ç°**
   ```typescript
   // backend-api/src/services/interruption.service.ts
   export class InterruptionService {
     private isDigitalHumanSpeaking = false;
     private currentTTSStream: NodeJS.ReadableStream | null = null;
     
     async handleUserInterruption() {
       if (this.isDigitalHumanSpeaking) {
         // åœæ­¢å½“å‰TTSæµ
         this.currentTTSStream?.destroy();
         this.isDigitalHumanSpeaking = false;
         
         // é€šçŸ¥å®¢æˆ·ç«¯åœæ­¢æ’­æ”¾
         this.io.emit('interrupt_digital_human');
       }
     }
     
     async startDigitalHumanSpeech(text: string) {
       this.isDigitalHumanSpeaking = true;
       
       // æµå¼ç”ŸæˆTTS
       const ttsStream = await this.ttsService.stream(text);
       this.currentTTSStream = ttsStream;
       
       // ç›‘å¬ç”¨æˆ·è¯­éŸ³ï¼Œå¦‚æœæ£€æµ‹åˆ°åˆ™æ‰“æ–­
       this.vadService.onSpeechStart(() => {
         this.handleUserInterruption();
       });
       
       // æµå¼å‘é€éŸ³é¢‘åˆ°å®¢æˆ·ç«¯
       ttsStream.on('data', (audioChunk) => {
         this.io.emit('digital_human_audio', audioChunk);
       });
       
       ttsStream.on('end', () => {
         this.isDigitalHumanSpeaking = false;
       });
     }
   }
   ```

---

## ğŸ“± Androidç«¯å®Œæ•´å®ç°ç¤ºä¾‹

```kotlin
// DigitalInterviewScreen.kt (å¢å¼ºç‰ˆ)
@Composable
fun DigitalInterviewScreen(
    uiState: DigitalInterviewUiState,
    onBackClick: () -> Unit
) {
    val context = LocalContext.current
    val rtcManager = remember { WebRTCManager(context) }
    val vadManager = remember { VADManager() }
    val interruptionHandler = remember { InterruptionHandler() }
    
    LaunchedEffect(Unit) {
        // åˆå§‹åŒ–RTCè¿æ¥
        rtcManager.initialize()
        
        // è®¾ç½®éŸ³é¢‘æ¥æ”¶å›è°ƒ
        rtcManager.onAudioReceived { audioData ->
            // é©±åŠ¨Live2Då˜´å‹
            driveLive2DWithAudio(audioData)
            
            // æ’­æ”¾éŸ³é¢‘
            playAudio(audioData)
        }
        
        // è®¾ç½®VADå›è°ƒ
        vadManager.onSpeechDetected { isSpeaking ->
            if (isSpeaking && interruptionHandler.isDigitalHumanSpeaking()) {
                // ç”¨æˆ·æ‰“æ–­æ•°å­—äºº
                interruptionHandler.interrupt()
                rtcManager.sendInterruptionSignal()
            }
        }
    }
    
    // UIç»„ä»¶...
    Box(modifier = Modifier.fillMaxSize()) {
        // Live2Dæ•°å­—äººè§†å›¾
        Live2DView(
            modifier = Modifier.align(Alignment.TopEnd),
            onAudioData = { audioData ->
                // åˆ†æéŸ³é¢‘é©±åŠ¨å˜´å‹
                animateMouthWithAudio(audioData)
            }
        )
        
        // è¯­éŸ³è¾“å…¥æŒ‰é’®
        VoiceInputButton(
            onStartRecording = {
                vadManager.startListening()
                rtcManager.startAudioCapture()
            },
            onStopRecording = {
                vadManager.stopListening()
                rtcManager.stopAudioCapture()
            },
            onAudioData = { audioData ->
                // å‘é€éŸ³é¢‘åˆ°æœåŠ¡å™¨
                rtcManager.sendAudioData(audioData)
            }
        )
    }
    
    DisposableEffect(Unit) {
        onDispose {
            rtcManager.cleanup()
            vadManager.cleanup()
        }
    }
}
```

---

## ğŸ§ª æµ‹è¯•å’Œè°ƒè¯•

### æµ‹è¯•æ‰“æ–­æœºåˆ¶

```kotlin
// æµ‹è¯•ç”¨ä¾‹
@Test
fun testInterruption() {
    // 1. æ•°å­—äººå¼€å§‹è¯´è¯
    digitalHumanManager.startSpeaking("è¿™æ˜¯ä¸€æ®µå¾ˆé•¿çš„å›ç­”...")
    
    // 2. æ¨¡æ‹Ÿç”¨æˆ·æ‰“æ–­
    Thread.sleep(1000)  // ç­‰å¾…1ç§’
    audioRecorder.record("æ‰“æ–­")  // ç”¨æˆ·è¯´è¯
    
    // 3. éªŒè¯æ•°å­—äººåœæ­¢è¯´è¯
    assertFalse(digitalHumanManager.isSpeaking())
    
    // 4. éªŒè¯ç”¨æˆ·è¯­éŸ³è¢«å¤„ç†
    assertTrue(speechRecognizer.isProcessing())
}
```

### æ€§èƒ½æŒ‡æ ‡

- **ç«¯åˆ°ç«¯å»¶è¿Ÿ**: < 500msï¼ˆç›®æ ‡ï¼‰
- **æ‰“æ–­å“åº”æ—¶é—´**: < 200msï¼ˆç›®æ ‡ï¼‰
- **éŸ³é¢‘è´¨é‡**: 16kHz, 16bit, PCM
- **VADå‡†ç¡®ç‡**: > 95%

---

## ğŸ“š å‚è€ƒèµ„æº

1. **FunASRæ–‡æ¡£**: https://github.com/alibaba-damo-academy/FunASR
2. **WebRTCå®˜æ–¹æ–‡æ¡£**: https://webrtc.org/getting-started/overview
3. **Live2D SDK**: https://www.live2d.com/sdk/download/cubism-sdk/
4. **DUIX.aiæ–‡æ¡£**: https://github.com/duix-cloud/duix-cloud-sdk

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **å»¶è¿Ÿä¼˜åŒ–**
   - ä½¿ç”¨æµå¼TTSè¾“å‡ºï¼Œä¸è¦ç­‰å¾…å®Œæ•´éŸ³é¢‘ç”Ÿæˆ
   - ä¼˜åŒ–ç½‘ç»œä¼ è¾“ï¼Œä½¿ç”¨UDPè€ŒéTCP
   - å‡å°‘éŸ³é¢‘ç¼“å†²ï¼Œä½¿ç”¨å°chunkä¼ è¾“

2. **æ‰“æ–­æœºåˆ¶ç²¾åº¦**
   - VADé˜ˆå€¼éœ€è¦æ ¹æ®å®é™…ç¯å¢ƒè°ƒæ•´
   - è€ƒè™‘èƒŒæ™¯å™ªéŸ³å’Œå›å£°æ¶ˆé™¤
   - å®ç°é˜²æŠ–æœºåˆ¶ï¼Œé¿å…è¯¯è§¦å‘

3. **èµ„æºç®¡ç†**
   - åŠæ—¶é‡Šæ”¾éŸ³é¢‘èµ„æº
   - æ§åˆ¶å¹¶å‘è¿æ¥æ•°
   - ç›‘æ§å†…å­˜å’ŒCPUä½¿ç”¨

4. **é”™è¯¯å¤„ç†**
   - ç½‘ç»œæ–­å¼€é‡è¿æœºåˆ¶
   - TTSå¤±è´¥é™çº§æ–¹æ¡ˆ
   - ASRè¯†åˆ«å¤±è´¥é‡è¯•é€»è¾‘

---

**ä¸‹ä¸€æ­¥**: æ ¹æ®æ‚¨çš„å…·ä½“éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ–¹æ¡ˆï¼Œå»ºè®®ä»æ–¹æ¡ˆä¸‰ï¼ˆæ¸è¿›å¼é›†æˆï¼‰å¼€å§‹ï¼Œé€æ­¥å®Œå–„åŠŸèƒ½ã€‚

