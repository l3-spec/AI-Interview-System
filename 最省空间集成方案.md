# æœ€çœç©ºé—´çš„é›†æˆæ–¹æ¡ˆ - ä¸å®‰è£…OpenAvatarChat

## ğŸ¯ æ–¹æ¡ˆæ¦‚è¿°

**ä¸å®‰è£…OpenAvatarChat**ï¼Œç›´æ¥åœ¨æ‚¨çš„ç°æœ‰Node.jsé¡¹ç›®ä¸­é›†æˆRTC + ASRåŠŸèƒ½ã€‚

### ä¼˜åŠ¿
- âœ… **æœ€çœç©ºé—´**ï¼šåªéœ€~100-200MBï¼ˆWebRTCåº“ï¼‰
- âœ… **é¿å…Pythonä¾èµ–**ï¼šå®Œå…¨ä½¿ç”¨Node.jsç”Ÿæ€
- âœ… **åˆ©ç”¨ç°æœ‰åŸºç¡€è®¾æ–½**ï¼šæ‚¨çš„LLMã€TTSã€æ•°å­—äººéƒ½å·²å°±ç»ª
- âœ… **æ›´ç¬¦åˆæ¶æ„**ï¼šç»Ÿä¸€çš„æŠ€æœ¯æ ˆ

---

## ğŸ“¦ éœ€è¦å®‰è£…çš„ä¾èµ–

```bash
cd backend-api
npm install wrtc socket.io --save
```

**ç©ºé—´å ç”¨**ï¼š~100-200MB

---

## ğŸ”§ å®ç°æ­¥éª¤

### 1. åˆ›å»ºRTCæœåŠ¡ï¼ˆNode.jsï¼‰

```typescript
// backend-api/src/services/rtc.service.ts
import { Server as SocketIOServer } from 'socket.io';
import { RTCPeerConnection, RTCSessionDescription, RTCIceCandidate } from 'wrtc';

export class RTCService {
  private io: SocketIOServer;
  private peerConnections: Map<string, RTCPeerConnection> = new Map();

  constructor(io: SocketIOServer) {
    this.io = io;
    this.setupRTC();
  }

  private setupRTC() {
    this.io.on('connection', (socket) => {
      console.log('ğŸ”— RTCå®¢æˆ·ç«¯è¿æ¥:', socket.id);

      // åˆ›å»ºWebRTCè¿æ¥
      socket.on('rtc-offer', async (offer: RTCSessionDescriptionInit) => {
        try {
          const pc = new RTCPeerConnection({
            iceServers: [
              { urls: 'stun:stun.l.google.com:19302' }
            ]
          });

          // å¤„ç†è¿œç¨‹éŸ³é¢‘æµ
          pc.ontrack = (event) => {
            console.log('ğŸ“¥ æ”¶åˆ°è¿œç¨‹éŸ³é¢‘æµ');
            // è¿™é‡Œå¯ä»¥å¤„ç†æ¥æ”¶åˆ°çš„éŸ³é¢‘æ•°æ®
            this.handleAudioStream(event.streams[0], socket.id);
          };

          // å¤„ç†ICEå€™é€‰
          pc.onicecandidate = (event) => {
            if (event.candidate) {
              socket.emit('rtc-ice-candidate', event.candidate);
            }
          };

          // è®¾ç½®è¿œç¨‹æè¿°
          await pc.setRemoteDescription(new RTCSessionDescription(offer));

          // åˆ›å»ºå›ç­”
          const answer = await pc.createAnswer();
          await pc.setLocalDescription(answer);

          socket.emit('rtc-answer', answer);
          this.peerConnections.set(socket.id, pc);

        } catch (error) {
          console.error('âŒ RTCè¿æ¥å¤±è´¥:', error);
          socket.emit('rtc-error', { message: error.message });
        }
      });

      // å¤„ç†ICEå€™é€‰
      socket.on('rtc-ice-candidate', async (candidate: RTCIceCandidateInit) => {
        const pc = this.peerConnections.get(socket.id);
        if (pc) {
          await pc.addIceCandidate(new RTCIceCandidate(candidate));
        }
      });

      // æ–­å¼€è¿æ¥
      socket.on('disconnect', () => {
        const pc = this.peerConnections.get(socket.id);
        if (pc) {
          pc.close();
          this.peerConnections.delete(socket.id);
        }
      });
    });
  }

  private async handleAudioStream(stream: MediaStream, socketId: string) {
    // å¤„ç†éŸ³é¢‘æµ
    // 1. æå–éŸ³é¢‘æ•°æ®
    // 2. å‘é€åˆ°ASRæœåŠ¡
    // 3. ç­‰å¾…LLMå“åº”
    // 4. TTSç”Ÿæˆè¯­éŸ³
    // 5. å‘é€å›å®¢æˆ·ç«¯
  }
}
```

### 2. é›†æˆASRæœåŠ¡ï¼ˆä½¿ç”¨é˜¿é‡Œäº‘APIï¼‰

```typescript
// backend-api/src/services/asr.service.ts
import axios from 'axios';
import FormData from 'form-data';

export class ASRService {
  private async recognizeWithAliyun(audioBuffer: Buffer): Promise<string> {
    // ä½¿ç”¨æ‚¨ç°æœ‰çš„é˜¿é‡Œäº‘ASRé…ç½®
    // å‚è€ƒæ‚¨é¡¹ç›®ä¸­çš„TTSæœåŠ¡å®ç°æ–¹å¼
    const formData = new FormData();
    formData.append('audio', audioBuffer, 'audio.wav');

    const response = await axios.post(
      'https://nls-gateway.cn-shanghai.aliyuncs.com/stream/v1/asr',
      formData,
      {
        headers: {
          'Authorization': `Bearer ${process.env.ALIYUN_ASR_TOKEN}`,
          ...formData.getHeaders()
        }
      }
    );

    return response.data.result;
  }

  async recognize(audioBuffer: Buffer): Promise<string> {
    // å¯ä»¥ä½¿ç”¨ç°æœ‰çš„é˜¿é‡Œäº‘ASR
    // æˆ–ä½¿ç”¨FunASRçš„HTTP APIï¼ˆä¸éœ€è¦æœ¬åœ°æ¨¡å‹ï¼‰
    return this.recognizeWithAliyun(audioBuffer);
  }
}
```

### 3. åˆ›å»ºå®æ—¶è¯­éŸ³å¤„ç†ç®¡é“

```typescript
// backend-api/src/services/realtime-voice-pipeline.service.ts
import { ASRService } from './asr.service';
import { TTSService } from './ttsService'; // æ‚¨ç°æœ‰çš„TTSæœåŠ¡
import { AIService } from './aiService'; // æ‚¨ç°æœ‰çš„AIæœåŠ¡

export class RealtimeVoicePipeline {
  private asrService: ASRService;
  private ttsService: TTSService;
  private aiService: AIService;
  private isDigitalHumanSpeaking = false;

  constructor() {
    this.asrService = new ASRService();
    this.ttsService = new TTSService();
    this.aiService = new AIService();
  }

  async processAudioStream(audioBuffer: Buffer, sessionId: string) {
    try {
      // 1. ASRè¯†åˆ«
      const text = await this.asrService.recognize(audioBuffer);
      
      // 2. æ£€æµ‹æ‰“æ–­ï¼ˆå¦‚æœæ•°å­—äººæ­£åœ¨è¯´è¯ï¼‰
      if (this.isDigitalHumanSpeaking && text.trim().length > 0) {
        this.handleInterruption();
      }

      // 3. LLMç”Ÿæˆå›å¤
      const response = await this.aiService.generateResponse(text, sessionId);

      // 4. TTSåˆæˆè¯­éŸ³
      const audioResult = await this.ttsService.textToSpeech({
        text: response,
        sessionId,
      });

      // 5. è¿”å›éŸ³é¢‘æ•°æ®
      return {
        audioUrl: audioResult.audioPath,
        text: response,
      };

    } catch (error) {
      console.error('è¯­éŸ³å¤„ç†å¤±è´¥:', error);
      throw error;
    }
  }

  private handleInterruption() {
    this.isDigitalHumanSpeaking = false;
    // åœæ­¢å½“å‰TTSæ’­æ”¾
    // é€šçŸ¥å®¢æˆ·ç«¯åœæ­¢æ’­æ”¾
  }
}
```

### 4. åœ¨WebSocketæœåŠ¡ä¸­é›†æˆ

```typescript
// backend-api/src/websocket/interview.websocket.ts
import { RTCService } from '../services/rtc.service';
import { RealtimeVoicePipeline } from '../services/realtime-voice-pipeline.service';

export class InterviewWebSocketServer {
  private rtcService: RTCService;
  private voicePipeline: RealtimeVoicePipeline;

  constructor(io: SocketIOServer) {
    this.rtcService = new RTCService(io);
    this.voicePipeline = new RealtimeVoicePipeline();
    
    this.setupHandlers(io);
  }

  private setupHandlers(io: SocketIOServer) {
    io.on('connection', (socket) => {
      // å¤„ç†éŸ³é¢‘æ•°æ®
      socket.on('audio-data', async (data: { audio: Buffer, sessionId: string }) => {
        try {
          const result = await this.voicePipeline.processAudioStream(
            Buffer.from(data.audio),
            data.sessionId
          );
          
          socket.emit('audio-response', result);
        } catch (error) {
          socket.emit('error', { message: error.message });
        }
      });
    });
  }
}
```

### 5. Androidç«¯é›†æˆï¼ˆç®€åŒ–ç‰ˆï¼‰

```kotlin
// Androidç«¯WebRTCè¿æ¥
class RealtimeVoiceManager {
    private var peerConnection: PeerConnection? = null
    
    suspend fun connectToServer() {
        val rtcConfig = PeerConnection.RTCConfiguration(
            listOf(
                PeerConnection.IceServer.builder("stun:stun.l.google.com:19302").createIceServer()
            )
        )
        
        peerConnection = PeerConnectionFactory.createPeerConnection(rtcConfig, object : PeerConnectionObserver() {
            override fun onTrack(event: RtpTransceiver?) {
                // æ¥æ”¶æœåŠ¡å™¨éŸ³é¢‘æµ
                if (event?.track is AudioTrack) {
                    val audioTrack = event.track as AudioTrack
                    // æ’­æ”¾éŸ³é¢‘å¹¶é©±åŠ¨Live2D
                    playAudioAndDriveLive2D(audioTrack)
                }
            }
        })
        
        // æ·»åŠ æœ¬åœ°éŸ³é¢‘è½¨é“
        val audioSource = PeerConnectionFactory.createAudioSource(MediaConstraints())
        val audioTrack = PeerConnectionFactory.createAudioTrack("audio_track", audioSource)
        peerConnection?.addTrack(audioTrack)
        
        // åˆ›å»ºofferå¹¶å‘é€åˆ°æœåŠ¡å™¨
        val offer = peerConnection?.createOffer()
        peerConnection?.setLocalDescription(offer)
        // é€šè¿‡WebSocketå‘é€offeråˆ°æœåŠ¡å™¨
    }
    
    private fun playAudioAndDriveLive2D(audioTrack: AudioTrack) {
        // æ’­æ”¾éŸ³é¢‘
        audioTrack.setSink { audioBuffer ->
            // åˆ†æéŸ³é¢‘é©±åŠ¨Live2Då˜´å‹
            analyzeAudioAndAnimate(audioBuffer)
        }
    }
}
```

---

## ğŸ“Š å¯¹æ¯”

| æ–¹æ¡ˆ | ç©ºé—´å ç”¨ | å¤æ‚åº¦ | æ¨èåº¦ |
|------|---------|--------|--------|
| **å®‰è£…OpenAvatarChat** | 5-10GB | é«˜ | â­â­ |
| **ä¸å®‰è£…ï¼Œç›´æ¥é›†æˆ** | ~200MB | ä¸­ | â­â­â­â­â­ |

---

## âœ… ä¼˜åŠ¿æ€»ç»“

1. **ç©ºé—´èŠ‚çœ**ï¼šä»5-10GBé™åˆ°200MB
2. **æŠ€æœ¯æ ˆç»Ÿä¸€**ï¼šå…¨éƒ¨ä½¿ç”¨Node.js + TypeScript
3. **åˆ©ç”¨ç°æœ‰ä»£ç **ï¼šæ‚¨çš„TTSã€LLMæœåŠ¡éƒ½å¯ä»¥å¤ç”¨
4. **æ˜“äºç»´æŠ¤**ï¼šä»£ç éƒ½åœ¨ä¸€ä¸ªé¡¹ç›®ä¸­
5. **éƒ¨ç½²ç®€å•**ï¼šä¸éœ€è¦Pythonç¯å¢ƒ

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

```bash
# 1. å®‰è£…ä¾èµ–ï¼ˆåªéœ€è¿™ä¸€æ­¥ï¼‰
cd backend-api
npm install wrtc socket.io --save

# 2. åˆ›å»ºä¸Šè¿°æœåŠ¡æ–‡ä»¶
# 3. åœ¨æ‚¨çš„WebSocketæœåŠ¡ä¸­é›†æˆ
# 4. Androidç«¯ä½¿ç”¨WebRTCè¿æ¥
```

**ç©ºé—´å ç”¨æ€»è®¡**ï¼š~200MBï¼ˆvs 5-10GBï¼‰

---

**è¿™ä¸ªæ–¹æ¡ˆæ›´é€‚åˆæ‚¨çš„ç£ç›˜ç©ºé—´é™åˆ¶ï¼**

