package com.xlwl.AiMian.ai.realtime

import android.content.Context
import android.media.AudioFormat
import android.media.AudioRecord
import android.media.MediaCodec
import android.media.MediaExtractor
import android.media.MediaFormat
import android.media.MediaPlayer
import android.media.MediaRecorder
import android.media.audiofx.Visualizer
import android.util.Log
import com.xlwl.AiMian.digitalhuman.DigitalHumanController
import io.socket.client.IO
import io.socket.client.Socket
import kotlinx.coroutines.CoroutineScope
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.Job
import kotlinx.coroutines.SupervisorJob
import kotlinx.coroutines.cancel
import kotlinx.coroutines.delay
import kotlinx.coroutines.launch
import kotlinx.coroutines.withContext
import kotlinx.coroutines.flow.MutableSharedFlow
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.SharedFlow
import kotlinx.coroutines.flow.StateFlow
import kotlinx.coroutines.flow.asSharedFlow
import kotlinx.coroutines.flow.asStateFlow
import kotlinx.coroutines.flow.update
import okhttp3.OkHttpClient
import okhttp3.Request
import org.json.JSONObject
import java.io.ByteArrayOutputStream
import java.io.File
import java.io.RandomAccessFile
import java.util.Locale
import java.util.UUID
import java.util.concurrent.TimeUnit
import kotlin.math.sqrt

enum class ConversationRole { USER, DIGITAL_HUMAN }

data class ConversationMessage(
    val id: String = UUID.randomUUID().toString(),
    val role: ConversationRole,
    val text: String,
    val timestamp: Long = System.currentTimeMillis()
)

enum class ConnectionState { DISCONNECTED, CONNECTING, CONNECTED }

class RealtimeVoiceManager(private val context: Context) {
    companion object {
        private const val TAG = "RealtimeVoiceManager"
        private const val SAMPLE_RATE = 16000
        private const val CHANNEL_CONFIG = AudioFormat.CHANNEL_IN_MONO
        private const val AUDIO_FORMAT = AudioFormat.ENCODING_PCM_16BIT
        private const val MAX_RECORDING_DURATION_MS = 60000  // æœ€é•¿å½•éŸ³60ç§’
        private const val VISUALIZER_MAX_RETRY = 5
        private const val VISUALIZER_RETRY_DELAY_MS = 150L
    }

    private suspend fun preparePlayableAudio(sourcePath: String): String? = withContext(Dispatchers.IO) {
        try {
            val localFile = if (sourcePath.startsWith("http", ignoreCase = true)) {
                downloadAudioToCache(sourcePath)
            } else {
                File(sourcePath)
            }
            if (localFile == null || !localFile.exists()) {
                Log.e(TAG, "éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: $sourcePath")
                return@withContext null
            }

            val ext = localFile.extension.lowercase(Locale.ROOT)
            if (ext == "wav" || ext == "pcm") {
                return@withContext localFile.absolutePath
            }

            // å°†mp3ç­‰æ ¼å¼è½¬ä¸ºwavï¼Œä¾¿äºDUIXæ­£å¸¸é©±åŠ¨å˜´å‹
            val wavPath = transcodeToWav(localFile)
            if (wavPath != null) {
                return@withContext wavPath
            }

            Log.w(TAG, "éŸ³é¢‘è½¬æ¢å¤±è´¥ï¼Œé€€å›åŸå§‹æ ¼å¼: $sourcePath")
            localFile.absolutePath
        } catch (e: Exception) {
            Log.e(TAG, "å‡†å¤‡éŸ³é¢‘å¤±è´¥", e)
            null
        }
    }

    private suspend fun downloadAudioToCache(url: String): File? = withContext(Dispatchers.IO) {
        return@withContext try {
            val request = Request.Builder().url(url).build()
            downloadClient.newCall(request).execute().use { response ->
                if (!response.isSuccessful) {
                    Log.e(TAG, "ä¸‹è½½éŸ³é¢‘å¤±è´¥: code=${response.code}, url=$url")
                    return@use null
                }
                val body = response.body ?: return@use null
                val suffix = url.substringAfterLast('.', "mp3").takeIf { it.length <= 5 } ?: "mp3"
                val file = File(context.cacheDir, "duix_audio_${System.currentTimeMillis()}.$suffix")
                file.outputStream().use { output ->
                    body.byteStream().copyTo(output)
                }
                Log.d(TAG, "éŸ³é¢‘ä¸‹è½½å®Œæˆ: ${file.absolutePath}")
                file
            }
        } catch (e: Exception) {
            Log.e(TAG, "ä¸‹è½½éŸ³é¢‘å¼‚å¸¸", e)
            null
        }
    }

    private fun transcodeToWav(input: File): String? {
        var extractor: MediaExtractor? = null
        var codec: MediaCodec? = null
        var raf: RandomAccessFile? = null
        return try {
            extractor = MediaExtractor().apply { setDataSource(input.absolutePath) }
            var audioTrack = -1
            for (i in 0 until extractor.trackCount) {
                val format = extractor.getTrackFormat(i)
                val mime = format.getString(MediaFormat.KEY_MIME) ?: ""
                if (mime.startsWith("audio/")) {
                    audioTrack = i
                    break
                }
            }
            if (audioTrack < 0) {
                Log.e(TAG, "æœªæ‰¾åˆ°éŸ³é¢‘è½¨é“ï¼Œæ— æ³•è½¬ç : ${input.absolutePath}")
                return null
            }
            extractor.selectTrack(audioTrack)
            val format = extractor.getTrackFormat(audioTrack)
            val mime = format.getString(MediaFormat.KEY_MIME) ?: return null
            val sampleRate = format.getInteger(MediaFormat.KEY_SAMPLE_RATE)
            val channelCount = format.getInteger(MediaFormat.KEY_CHANNEL_COUNT)

            codec = MediaCodec.createDecoderByType(mime)
            codec.configure(format, null, null, 0)
            codec.start()

            val bufferInfo = MediaCodec.BufferInfo()
            val outputFile = File(context.cacheDir, "duix_audio_${System.currentTimeMillis()}.wav")
            raf = RandomAccessFile(outputFile, "rw").apply {
                // é¢„ç•™å¤´éƒ¨
                setLength(0)
                write(ByteArray(44))
            }

            var totalPcmBytes = 0
            val timeoutUs = 10_000L
            var sawInputEOS = false
            var sawOutputEOS = false

            while (!sawOutputEOS) {
                if (!sawInputEOS) {
                    val inputIndex = codec.dequeueInputBuffer(timeoutUs)
                    if (inputIndex >= 0) {
                        val inputBuffer = codec.getInputBuffer(inputIndex) ?: continue
                        val sampleSize = extractor.readSampleData(inputBuffer, 0)
                        if (sampleSize < 0) {
                            codec.queueInputBuffer(
                                inputIndex,
                                0,
                                0,
                                0,
                                MediaCodec.BUFFER_FLAG_END_OF_STREAM
                            )
                            sawInputEOS = true
                        } else {
                            val presentationTimeUs = extractor.sampleTime
                            codec.queueInputBuffer(
                                inputIndex,
                                0,
                                sampleSize,
                                presentationTimeUs,
                                extractor.sampleFlags
                            )
                            extractor.advance()
                        }
                    }
                }

                var outputIndex = codec.dequeueOutputBuffer(bufferInfo, timeoutUs)
                while (outputIndex >= 0) {
                    val outBuffer = codec.getOutputBuffer(outputIndex)
                    if (bufferInfo.size > 0 && outBuffer != null) {
                        val chunk = ByteArray(bufferInfo.size)
                        outBuffer.get(chunk)
                        outBuffer.clear()
                        raf.seek(44 + totalPcmBytes.toLong())
                        raf.write(chunk)
                        totalPcmBytes += chunk.size
                    }
                    codec.releaseOutputBuffer(outputIndex, false)
                    if (bufferInfo.flags and MediaCodec.BUFFER_FLAG_END_OF_STREAM != 0) {
                        sawOutputEOS = true
                        break
                    }
                    outputIndex = codec.dequeueOutputBuffer(bufferInfo, timeoutUs)
                }
            }

            // å†™å…¥WAVå¤´
            raf.seek(0)
            writeWavHeader(raf, sampleRate, channelCount, totalPcmBytes)
            Log.d(TAG, "è½¬ç å®Œæˆ: ${outputFile.absolutePath} (pcmBytes=$totalPcmBytes)")
            outputFile.absolutePath
        } catch (e: Exception) {
            Log.e(TAG, "éŸ³é¢‘è½¬ç å¤±è´¥: ${input.absolutePath}", e)
            null
        } finally {
            try { extractor?.release() } catch (_: Exception) {}
            try { codec?.stop(); codec?.release() } catch (_: Exception) {}
            try { raf?.close() } catch (_: Exception) {}
        }
    }

    private fun writeWavHeader(raf: RandomAccessFile, sampleRate: Int, channels: Int, pcmDataLength: Int) {
        val byteRate = sampleRate * channels * 16 / 8
        val totalDataLen = pcmDataLength + 36
        val blockAlign = channels * 16 / 8

        raf.writeBytes("RIFF")
        raf.writeIntLE(totalDataLen)
        raf.writeBytes("WAVE")
        raf.writeBytes("fmt ")
        raf.writeIntLE(16) // Subchunk1Size for PCM
        raf.writeShortLE(1) // PCM format
        raf.writeShortLE(channels.toShort().toInt())
        raf.writeIntLE(sampleRate)
        raf.writeIntLE(byteRate)
        raf.writeShortLE(blockAlign.toShort().toInt())
        raf.writeShortLE(16) // bits per sample
        raf.writeBytes("data")
        raf.writeIntLE(pcmDataLength)
        raf.setLength((pcmDataLength + 44).toLong())
    }

    private fun RandomAccessFile.writeIntLE(value: Int) {
        write(byteArrayOf(
            (value and 0xFF).toByte(),
            ((value shr 8) and 0xFF).toByte(),
            ((value shr 16) and 0xFF).toByte(),
            ((value shr 24) and 0xFF).toByte()
        ))
    }

    private fun RandomAccessFile.writeShortLE(value: Int) {
        write(byteArrayOf(
            (value and 0xFF).toByte(),
            ((value shr 8) and 0xFF).toByte()
        ))
    }

    private val scope = CoroutineScope(Dispatchers.IO + SupervisorJob())
    private val aliyunSpeechService = AliyunSpeechService(context.applicationContext)
    
    // VADæ£€æµ‹å™¨
    private val vadDetector = VoiceActivityDetector(
        sampleRate = SAMPLE_RATE,
        silenceThresholdDb = -40f,      // å¯ä»¥é€šè¿‡é…ç½®è°ƒæ•´
        silenceDurationMs = 2000,        // 2ç§’é™éŸ³åè‡ªåŠ¨ç»“æŸ
        speechMinDurationMs = 500,       // è‡³å°‘è¯´0.5ç§’
        maxSpeechDurationMs = MAX_RECORDING_DURATION_MS.toLong()
    )
    
    private var vadEnabled = true  // VADæ˜¯å¦å¯ç”¨

    private var socket: Socket? = null
    private var audioRecord: AudioRecord? = null
    private var mediaPlayer: MediaPlayer? = null
    private var visualizer: Visualizer? = null
    private var digitalHumanController: DigitalHumanController? = null
    private var recordingJob: Job? = null
    private var currentSessionId: String? = null
    private var currentUserId: String? = null
    private var currentJobPosition: String? = null
    private var currentBackground: String? = null
    private var isInitializingSocket = false
    private var lastInitAttemptAt: Long = 0
    private var isRecording = false
    private var recordedBuffer: ByteArrayOutputStream? = null
    
    // é˜²é‡å¤æ’­æ”¾æœºåˆ¶ï¼šè®°å½•å·²æ’­æ”¾çš„æ–‡æœ¬ï¼ˆä½¿ç”¨æ–‡æœ¬å†…å®¹çš„hashï¼‰
    private val playedTextHashes = mutableSetOf<String>()
    private var currentPlayingTextHash: String? = null

    private val _connectionState = MutableStateFlow(ConnectionState.DISCONNECTED)
    val connectionState: StateFlow<ConnectionState> = _connectionState.asStateFlow()

    private val _isRecordingFlow = MutableStateFlow(false)
    val isRecordingFlow: StateFlow<Boolean> = _isRecordingFlow.asStateFlow()

    private val _isDigitalHumanSpeaking = MutableStateFlow(false)
    val isDigitalHumanSpeaking: StateFlow<Boolean> = _isDigitalHumanSpeaking.asStateFlow()

    private val _isProcessing = MutableStateFlow(false)
    val isProcessing: StateFlow<Boolean> = _isProcessing.asStateFlow()

    private val _partialTranscript = MutableStateFlow("")
    val partialTranscript: StateFlow<String> = _partialTranscript.asStateFlow()

    private val _conversation = MutableStateFlow<List<ConversationMessage>>(emptyList())
    val conversation: StateFlow<List<ConversationMessage>> = _conversation.asStateFlow()

    private val _latestDigitalHumanText = MutableStateFlow<String?>(null)
    val latestDigitalHumanText: StateFlow<String?> = _latestDigitalHumanText.asStateFlow()

    private val _interviewCompleted = MutableStateFlow(false)
    val interviewCompleted: StateFlow<Boolean> = _interviewCompleted.asStateFlow()

    private val _errors = MutableSharedFlow<String>(extraBufferCapacity = 1)
    val errors: SharedFlow<String> = _errors.asSharedFlow()

    private val completionKeywords = listOf(
        "é¢è¯•ç»“æŸ",
        "ç»“æŸé¢è¯•",
        "æœ¬æ¬¡é¢è¯•åˆ°æ­¤ç»“æŸ",
        "interview finished",
        "interview is over",
        "session completed"
    )

    // å¯é€‰çš„æ•°å­—äººéŸ³é¢‘åˆ†å‘ï¼ˆç”¨äºDUIXæ¨é€PCM/WAVï¼‰
    private var duixAudioSink: ((String) -> Unit)? = null

    private val downloadClient by lazy {
        OkHttpClient.Builder()
            .connectTimeout(15, TimeUnit.SECONDS)
            .readTimeout(30, TimeUnit.SECONDS)
            .build()
    }

    suspend fun initialize(
        serverUrl: String,
        sessionId: String,
        userId: String? = null,
        jobPosition: String? = null,
        background: String? = null
    ): Boolean = withContext(Dispatchers.IO) {
        try {
            if (isInitializingSocket) {
                Log.w(TAG, "å·²æœ‰WebSocketåˆå§‹åŒ–è¿›è¡Œä¸­ï¼Œå¿½ç•¥é‡å¤è¯·æ±‚")
                return@withContext false
            }
            if (_connectionState.value == ConnectionState.CONNECTING) {
                Log.w(TAG, "WebSocketæ­£åœ¨è¿æ¥ï¼Œå¿½ç•¥é‡å¤åˆå§‹åŒ–è¯·æ±‚")
                return@withContext false
            }
            if (socket?.connected() == true && currentSessionId == sessionId) {
                Log.d(TAG, "å·²è¿æ¥åˆ°ç›¸åŒä¼šè¯ï¼Œè·³è¿‡é‡å¤åˆå§‹åŒ–")
                return@withContext true
            }
            val now = System.currentTimeMillis()
            if (now - lastInitAttemptAt < 4000) {
                Log.w(TAG, "åˆå§‹åŒ–è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œç¨åé‡è¯•")
                return@withContext false
            }
            lastInitAttemptAt = now
            isInitializingSocket = true

            // æ¸…ç†æ—§è¿æ¥ï¼Œé¿å…å¤šä¸ªSocketå¹¶è¡Œé‡è¿å¯¼è‡´è¿æ¥é£æš´
            try {
                socket?.off()
                socket?.disconnect()
            } catch (_: Exception) {
            }
            socket = null

            currentSessionId = sessionId
            currentUserId = userId
            currentJobPosition = jobPosition
            currentBackground = background
            _connectionState.value = ConnectionState.CONNECTING
            _interviewCompleted.value = false
            playedTextHashes.clear()
            currentPlayingTextHash = null

            val options = IO.Options().apply {
                forceNew = true
                // ç¦ç”¨è‡ªåŠ¨é‡è¿ï¼Œé¿å…åŒæ—¶å­˜åœ¨å¤šä¸ªSocketé‡è¿å¯¼è‡´è¿æ¥é£æš´ã€‚ç”±ä¸Šå±‚æ˜¾å¼æ§åˆ¶é‡è¿èŠ‚å¥ã€‚
                reconnection = false
                reconnectionAttempts = 0
                reconnectionDelay = 0
                reconnectionDelayMax = 0
                randomizationFactor = 0.0
                transports = arrayOf("websocket") // å¼ºåˆ¶ä½¿ç”¨websocketï¼Œé¿å…pollingå¯¼è‡´çš„transport error
            }

            val newSocket = IO.socket(serverUrl, options)
            newSocket.on(Socket.EVENT_CONNECT) {
                Log.d(TAG, "WebSocketè¿æ¥æˆåŠŸ: $serverUrl")
                _connectionState.value = ConnectionState.CONNECTED
                joinSession(sessionId, userId, jobPosition, background)
            }
            newSocket.on(Socket.EVENT_DISCONNECT) {
                Log.d(TAG, "WebSocketè¿æ¥æ–­å¼€")
                _connectionState.value = ConnectionState.DISCONNECTED
                socket = null
            }
            newSocket.on(Socket.EVENT_CONNECT_ERROR) { args ->
                Log.e(TAG, "WebSocketè¿æ¥é”™è¯¯: ${args.getOrNull(0)}")
                _connectionState.value = ConnectionState.DISCONNECTED
                socket = null
                args.getOrNull(0)?.toString()?.let { _errors.tryEmit(it) }
            }
            newSocket.on("voice_response") { args ->
                handleVoiceResponse(args[0] as JSONObject)
            }
            newSocket.on("status") { args ->
                handleStatus(args[0] as JSONObject)
            }
            newSocket.on("error") { args ->
                handleError(args.getOrNull(0))
            }

            Log.d(TAG, "å°è¯•è¿æ¥å®æ—¶è¯­éŸ³æœåŠ¡: $serverUrl (session=$sessionId)")
            newSocket.connect()
            socket = newSocket
            true
        } catch (e: Exception) {
            Log.e(TAG, "åˆå§‹åŒ–å®æ—¶è¯­éŸ³æœåŠ¡å¤±è´¥", e)
            _errors.tryEmit(e.message ?: "å®æ—¶è¯­éŸ³æœåŠ¡è¿æ¥å¤±è´¥")
            _connectionState.value = ConnectionState.DISCONNECTED
            false
        } finally {
            isInitializingSocket = false
        }
    }

    fun setDigitalHumanController(controller: DigitalHumanController?) {
        digitalHumanController = controller
        Log.i(TAG, "DigitalHumanControllerå·²è®¾ç½®: ${if (controller != null) "æˆåŠŸ" else "null"}")

        controller?.resetMouth()
        if (controller != null) {
            scope.launch {
                delay(500)
                Log.d(TAG, "æµ‹è¯•æ•°å­—äººå˜´å‹ï¼šè®¾ç½®ä¸º0.5")
                controller.updateMouthOpenness(0.5f)
                delay(500)
                Log.d(TAG, "æµ‹è¯•æ•°å­—äººå˜´å‹ï¼šé‡ç½®ä¸º0")
                controller.updateMouthOpenness(0f)
                Log.i(TAG, "âœ… æ•°å­—äººå˜´å‹æµ‹è¯•å®Œæˆ")
            }
        }
    }

    fun setDuixAudioSink(sink: ((String) -> Unit)?) {
        duixAudioSink = sink
    }

    /**
     * å¯åŠ¨VADæ™ºèƒ½å½•éŸ³
     * è‡ªåŠ¨æ£€æµ‹è¯´è¯å’Œé™éŸ³ï¼Œæ™ºèƒ½ç»“æŸå½•éŸ³
     */
    fun startRecording() {
        Log.d(TAG, "startRecordingè¢«è°ƒç”¨ - vadEnabled=$vadEnabled, isRecording=$isRecording, connectionState=${_connectionState.value}, sessionId=$currentSessionId")

        if (_interviewCompleted.value) {
            Log.w(TAG, "é¢è¯•å·²ç»“æŸï¼Œå¿½ç•¥å½•éŸ³è¯·æ±‚")
            return
        }

        if (isRecording) {
            Log.w(TAG, "æ­£åœ¨å½•éŸ³ï¼Œå¿½ç•¥é‡å¤è¯·æ±‚")
            return
        }
        if (_connectionState.value != ConnectionState.CONNECTED) {
            Log.e(TAG, "è¯­éŸ³æœåŠ¡å°šæœªè¿æ¥ï¼Œæ— æ³•å¼€å§‹å½•éŸ³")
            _errors.tryEmit("è¯­éŸ³æœåŠ¡å°šæœªè¿æ¥")
            return
        }
        val sessionId = currentSessionId
        if (sessionId.isNullOrBlank()) {
            Log.e(TAG, "ä¼šè¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•å¼€å§‹å½•éŸ³")
            _errors.tryEmit("ä¼šè¯æœªåˆå§‹åŒ–")
            return
        }

        Log.i(TAG, "å¼€å§‹åˆå§‹åŒ–å½•éŸ³ - sessionId=$sessionId, VAD=${if (vadEnabled) "å¯ç”¨" else "å…³é—­"}")
        scope.launch {
            try {
                val minBuffer = AudioRecord.getMinBufferSize(SAMPLE_RATE, CHANNEL_CONFIG, AUDIO_FORMAT)
                Log.d(TAG, "AudioRecordæœ€å°ç¼“å†²åŒºå¤§å°: $minBuffer")
                
                val bufferSize = if (minBuffer == AudioRecord.ERROR || minBuffer == AudioRecord.ERROR_BAD_VALUE) {
                    Log.w(TAG, "è·å–æœ€å°ç¼“å†²åŒºå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                    SAMPLE_RATE * 2
                } else {
                    minBuffer * 2
                }
                
                Log.d(TAG, "åˆ›å»ºAudioRecord - sampleRate=$SAMPLE_RATE, bufferSize=$bufferSize")
                val recorder = AudioRecord(
                    MediaRecorder.AudioSource.MIC,
                    SAMPLE_RATE,
                    CHANNEL_CONFIG,
                    AUDIO_FORMAT,
                    bufferSize
                )
                
                if (recorder.state != AudioRecord.STATE_INITIALIZED) {
                    Log.e(TAG, "éº¦å…‹é£åˆå§‹åŒ–å¤±è´¥ï¼Œstate=${recorder.state}")
                    _errors.tryEmit("éº¦å…‹é£åˆå§‹åŒ–å¤±è´¥")
                    recorder.release()
                    return@launch
                }
                
                Log.i(TAG, "AudioRecordåˆå§‹åŒ–æˆåŠŸï¼Œå¼€å§‹å½•éŸ³")
                
                // é‡ç½®VAD
                if (vadEnabled) {
                    vadDetector.reset()
                }
                
                recordedBuffer = ByteArrayOutputStream()
                audioRecord = recorder
                recorder.startRecording()
                isRecording = true
                _isRecordingFlow.value = true
                _partialTranscript.value = if (vadEnabled) "æ­£åœ¨è†å¬ï¼Œè¯·å¼€å§‹è¯´è¯..." else ""
                
                recordingJob = if (vadEnabled) {
                    launch { recordWithVad(recorder, sessionId) }
                } else {
                    launch { recordAndBufferAudio(recorder, sessionId) }
                }
                
                Log.i(TAG, "å½•éŸ³å·²å¯åŠ¨")
            } catch (e: Exception) {
                Log.e(TAG, "å¯åŠ¨å½•éŸ³å¤±è´¥", e)
                _errors.tryEmit(e.message ?: "å¯åŠ¨å½•éŸ³å¤±è´¥")
                stopRecordingInternal()
            }
        }
    }
    
    /**
     * è®¾ç½®VADæ˜¯å¦å¯ç”¨
     */
    fun setVadEnabled(enabled: Boolean) {
        vadEnabled = enabled
        Log.d(TAG, "VADæ¨¡å¼${if (enabled) "å·²å¯ç”¨" else "å·²å…³é—­"}")
    }
    
    /**
     * è·å–VADæ˜¯å¦å¯ç”¨
     */
    fun isVadEnabled(): Boolean = vadEnabled

    fun stopRecording() {
        Log.d(TAG, "stopRecordingè¢«è°ƒç”¨ - isRecording=$isRecording")
        if (!isRecording) {
            Log.w(TAG, "å½“å‰æœªåœ¨å½•éŸ³ï¼Œå¿½ç•¥åœæ­¢è¯·æ±‚")
            return
        }
        Log.i(TAG, "åœæ­¢å½•éŸ³")
        isRecording = false
        try {
            audioRecord?.stop()
        } catch (e: Exception) {
            Log.e(TAG, "åœæ­¢å½•éŸ³æ—¶å‡ºé”™", e)
        }
    }

    fun interrupt() {
        try {
            socket?.emit("interrupt")
        } catch (e: Exception) {
            Log.e(TAG, "å‘é€æ‰“æ–­è¯·æ±‚å¤±è´¥", e)
        }
    }

    fun cleanup() {
        try {
            socket?.disconnect()
            socket = null
        } catch (_: Exception) {
        }
        recordingJob?.cancel()
        recordingJob = null
        stopRecordingInternal()
        releaseVisualizer()
        mediaPlayer?.release()
        mediaPlayer = null
        digitalHumanController = null
        
        // æ¸…ç†é˜²é‡å¤æ’­æ”¾æ ‡è®°
        playedTextHashes.clear()
        currentPlayingTextHash = null
        _interviewCompleted.value = false

        scope.cancel()
    }

    /**
     * å¸¦VADçš„æ™ºèƒ½å½•éŸ³å¾ªç¯
     */
    private suspend fun recordWithVad(recorder: AudioRecord, sessionId: String) = withContext(Dispatchers.IO) {
        val buffer = ByteArray(2048)
        var totalBytes = 0
        var speechDetected = false
        var recordingStartTime = System.currentTimeMillis()
        
        Log.d(TAG, "å¼€å§‹VADæ™ºèƒ½å½•éŸ³å¾ªç¯ - sessionId=$sessionId")
        _partialTranscript.value = "æ­£åœ¨è†å¬ï¼Œè¯·å¼€å§‹è¯´è¯..."
        
        try {
            while (isRecording) {
                val bytesRead = recorder.read(buffer, 0, buffer.size)
                
                if (bytesRead > 0) {
                    // VADåˆ†æ
                    val vadResult = vadDetector.analyze(buffer)
                    
                    // æ ¹æ®VADçŠ¶æ€æ›´æ–°UI
                    when (vadResult.state) {
                        VoiceActivityDetector.State.IDLE -> {
                            _partialTranscript.value = "æ­£åœ¨è†å¬ï¼Œè¯·å¼€å§‹è¯´è¯..."
                        }
                        
                        VoiceActivityDetector.State.SPEECH_START -> {
                            if (!speechDetected) {
                                speechDetected = true
                                Log.i(TAG, "æ£€æµ‹åˆ°è¯´è¯ï¼Œå¼€å§‹å½•éŸ³ç¼“å†²")
                            }
                            _partialTranscript.value = "æ£€æµ‹åˆ°è¯´è¯ï¼Œæ­£åœ¨å½•éŸ³... (${vadResult.db.toInt()}dB)"
                        }
                        
                        VoiceActivityDetector.State.SPEECH -> {
                            val durationSec = vadResult.speechDuration / 1000
                            _partialTranscript.value = "æ­£åœ¨å½•éŸ³... ${durationSec}ç§’ (${vadResult.db.toInt()}dB)"
                            
                            // ç¼“å†²éŸ³é¢‘æ•°æ®
                            recordedBuffer?.write(buffer, 0, bytesRead)
                            totalBytes += bytesRead
                            
                            if (totalBytes % 32768 == 0) {
                                Log.d(TAG, "å·²å½•éŸ³: ${totalBytes / 1024}KB, æ—¶é•¿: ${durationSec}ç§’")
                            }
                        }
                        
                        VoiceActivityDetector.State.SPEECH_END -> {
                            Log.i(TAG, "æ£€æµ‹åˆ°è¯´è¯ç»“æŸ - æ—¶é•¿: ${vadResult.speechDuration}ms, æ•°æ®: ${totalBytes}å­—èŠ‚")
                            _partialTranscript.value = "è¯´è¯ç»“æŸï¼Œæ­£åœ¨è¯†åˆ«..."
                            isRecording = false
                            break
                        }
                    }
                    
                    // è¶…æ—¶ä¿æŠ¤
                    val elapsed = System.currentTimeMillis() - recordingStartTime
                    if (elapsed >= MAX_RECORDING_DURATION_MS) {
                        Log.w(TAG, "å½•éŸ³è¶…æ—¶ï¼Œå¼ºåˆ¶ç»“æŸ - æ—¶é•¿: ${elapsed}ms")
                        isRecording = false
                        break
                    }
                    
                } else if (bytesRead < 0) {
                    Log.e(TAG, "å½•éŸ³è¯»å–å¤±è´¥: bytesRead=$bytesRead")
                    _errors.tryEmit("å½•éŸ³è¯»å–å¤±è´¥: $bytesRead")
                    break
                }
            }
        } catch (e: Exception) {
            Log.e(TAG, "VADå½•éŸ³è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸", e)
            _errors.tryEmit(e.message ?: "å½•éŸ³å¤±è´¥")
        } finally {
            Log.i(TAG, "VADå½•éŸ³å¾ªç¯ç»“æŸ - æ€»å­—èŠ‚æ•°: $totalBytes, ç»Ÿè®¡: ${vadDetector.getStatistics()}")
            
            try {
                recorder.stop()
            } catch (e: Exception) {
                Log.e(TAG, "åœæ­¢recorderæ—¶å‡ºé”™", e)
            }
            recorder.release()
            audioRecord = null
            isRecording = false
            _isRecordingFlow.value = false
            
            // åªæœ‰æ£€æµ‹åˆ°æœ‰æ•ˆè¯­éŸ³æ‰å¤„ç†
            if (speechDetected && totalBytes > 0) {
                processRecordedAudio(true, sessionId)
            } else {
                Log.w(TAG, "æœªæ£€æµ‹åˆ°æœ‰æ•ˆè¯­éŸ³ï¼Œå–æ¶ˆå¤„ç†")
                _partialTranscript.value = ""
                recordedBuffer?.reset()
                recordedBuffer = null
            }
        }
    }
    
    /**
     * æ‰‹åŠ¨æ¨¡å¼å½•éŸ³å¾ªç¯ï¼ˆä¸ä½¿ç”¨VADï¼‰
     */
    private suspend fun recordAndBufferAudio(recorder: AudioRecord, sessionId: String) = withContext(Dispatchers.IO) {
        val buffer = ByteArray(2048)
        var totalBytes = 0
        Log.d(TAG, "å¼€å§‹æ‰‹åŠ¨æ¨¡å¼å½•éŸ³å¾ªç¯ - sessionId=$sessionId")
        
        try {
            while (isRecording) {
                val bytesRead = recorder.read(buffer, 0, buffer.size)
                if (bytesRead > 0) {
                    recordedBuffer?.write(buffer, 0, bytesRead)
                    totalBytes += bytesRead
                    if (totalBytes % 32768 == 0) { // æ¯32KBæ‰“å°ä¸€æ¬¡æ—¥å¿—
                        Log.d(TAG, "å·²å½•éŸ³: ${totalBytes / 1024}KB")
                    }
                } else if (bytesRead < 0) {
                    Log.e(TAG, "å½•éŸ³è¯»å–å¤±è´¥: bytesRead=$bytesRead")
                    _errors.tryEmit("å½•éŸ³è¯»å–å¤±è´¥: $bytesRead")
                    break
                }
            }
        } catch (e: Exception) {
            Log.e(TAG, "å½•éŸ³è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸", e)
            _errors.tryEmit(e.message ?: "å½•éŸ³å¤±è´¥")
        } finally {
            Log.i(TAG, "å½•éŸ³å¾ªç¯ç»“æŸ - æ€»å­—èŠ‚æ•°: $totalBytes")
            try {
                recorder.stop()
            } catch (e: Exception) {
                Log.e(TAG, "åœæ­¢recorderæ—¶å‡ºé”™", e)
            }
            recorder.release()
            audioRecord = null
            isRecording = false
            _isRecordingFlow.value = false
            processRecordedAudio(totalBytes > 0, sessionId)
        }
    }

    private suspend fun processRecordedAudio(hasAudio: Boolean, sessionId: String) {
        Log.d(TAG, "processRecordedAudioè¢«è°ƒç”¨ - hasAudio=$hasAudio, sessionId=$sessionId")
        
        val audioBytes = recordedBuffer?.toByteArray() ?: ByteArray(0)
        recordedBuffer?.reset()
        recordedBuffer = null
        
        Log.d(TAG, "éŸ³é¢‘æ•°æ®å¤§å°: ${audioBytes.size} bytes (${audioBytes.size / 1024}KB)")
        
        if (!hasAudio || audioBytes.isEmpty()) {
            Log.w(TAG, "æœªæ£€æµ‹åˆ°æœ‰æ•ˆéŸ³é¢‘")
            _errors.tryEmit("æœªæ£€æµ‹åˆ°æœ‰æ•ˆéŸ³é¢‘")
            return
        }
        
        _partialTranscript.value = "æ­£åœ¨è¯†åˆ«..."
        _isProcessing.value = true
        
        try {
            Log.i(TAG, "å¼€å§‹è°ƒç”¨é˜¿é‡Œäº‘ASR - éŸ³é¢‘å¤§å°: ${audioBytes.size} bytes")
            val text = aliyunSpeechService.recognizePcm(audioBytes).trim()
            Log.i(TAG, "ASRè¯†åˆ«ç»“æœ: $text")
            
            if (text.isEmpty()) {
                Log.w(TAG, "ASRæœªè¯†åˆ«åˆ°è¯­éŸ³å†…å®¹")
                _partialTranscript.value = ""
                _isProcessing.value = false
                _errors.tryEmit("æœªè¯†åˆ«åˆ°è¯­éŸ³å†…å®¹")
                return
            }
            
            _partialTranscript.value = text
            Log.i(TAG, "å‡†å¤‡æäº¤ç”¨æˆ·æ–‡æœ¬: $text")
            submitUserText(text)
        } catch (e: Exception) {
            Log.e(TAG, "é˜¿é‡Œäº‘ASRå¤±è´¥", e)
            _partialTranscript.value = ""
            _isProcessing.value = false
            _errors.tryEmit(e.message ?: "è¯­éŸ³è¯†åˆ«å¤±è´¥")
        }
    }

    private fun handleVoiceResponse(data: JSONObject) {
        Log.d(TAG, "handleVoiceResponseè¢«è°ƒç”¨ - data=$data")
        
        try {
            val audioUrl = data.optString("audioUrl", null)
            val text = data.optString("text", "")
            val ttsMode = data.optString("ttsMode", if (audioUrl.isNullOrBlank()) "client" else "server")
            val userText = data.optString("userText", "")
            val isCompletedFlag = data.optBoolean("isCompleted", false) ||
                data.optString("status").equals("completed", ignoreCase = true) ||
                data.optString("event").equals("completed", ignoreCase = true)

            Log.i(TAG, "æ”¶åˆ°è¯­éŸ³å“åº” - text=$text, ttsMode=$ttsMode, audioUrl=$audioUrl")

            // ç”Ÿæˆæ–‡æœ¬çš„å”¯ä¸€æ ‡è¯†ï¼ˆä½¿ç”¨æ–‡æœ¬å†…å®¹çš„hashï¼‰
            val textHash = if (text.isNotBlank()) {
                text.hashCode().toString() + "_" + text.length
            } else if (!audioUrl.isNullOrBlank()) {
                audioUrl.hashCode().toString()
            } else {
                null
            }
            
            // é˜²é‡å¤æ£€æŸ¥ï¼šå¦‚æœæ­£åœ¨æ’­æ”¾ç›¸åŒçš„æ–‡æœ¬ï¼Œè·³è¿‡
            if (textHash != null) {
                if (currentPlayingTextHash == textHash) {
                    Log.w(TAG, "âš ï¸ æ£€æµ‹åˆ°é‡å¤çš„è¯­éŸ³å“åº”ï¼ˆæ­£åœ¨æ’­æ”¾ä¸­ï¼‰ï¼Œè·³è¿‡ - textHash=$textHash")
                    return
                }
                
                if (playedTextHashes.contains(textHash)) {
                    Log.w(TAG, "âš ï¸ æ£€æµ‹åˆ°é‡å¤çš„è¯­éŸ³å“åº”ï¼ˆå·²æ’­æ”¾è¿‡ï¼‰ï¼Œè·³è¿‡ - textHash=$textHash")
                    return
                }
                
                // æ ‡è®°ä¸ºæ­£åœ¨æ’­æ”¾
                currentPlayingTextHash = textHash
            }

            _partialTranscript.value = ""
            _isProcessing.value = false

            if (userText.isNotBlank()) {
                appendMessage(ConversationMessage(role = ConversationRole.USER, text = userText))
            }
            appendMessage(ConversationMessage(role = ConversationRole.DIGITAL_HUMAN, text = text))
            _latestDigitalHumanText.value = text

            val completionHint = isCompletedFlag || completionKeywords.any { keyword ->
                text.contains(keyword, ignoreCase = true)
            }
            if (completionHint) {
                markInterviewCompleted("voice-response")
            }

            if (ttsMode.equals("client", ignoreCase = true)) {
                Log.i(TAG, "ä½¿ç”¨å®¢æˆ·ç«¯TTSæ’­æ”¾ - textHash=$textHash")
                playClientSideTts(text, textHash)
            } else if (!audioUrl.isNullOrBlank()) {
                Log.i(TAG, "ä½¿ç”¨æœåŠ¡å™¨ç«¯TTSéŸ³é¢‘ - url=$audioUrl, textHash=$textHash")
                playAudioFromPath(audioUrl, textHash, text)
            } else {
                Log.w(TAG, "æœªæä¾›å¯æ’­æ”¾çš„éŸ³é¢‘æ•°æ®")
                // å¦‚æœæ²¡æœ‰éŸ³é¢‘æ•°æ®ï¼Œæ¸…é™¤æ’­æ”¾æ ‡è®°
                currentPlayingTextHash = null
            }
        } catch (e: Exception) {
            Log.e(TAG, "å¤„ç†è¯­éŸ³å“åº”å¤±è´¥", e)
            _errors.tryEmit(e.message ?: "å¤„ç†è¯­éŸ³å“åº”å¤±è´¥")
            // å‡ºé”™æ—¶æ¸…é™¤æ’­æ”¾æ ‡è®°
            currentPlayingTextHash = null
        }
    }

    private fun handleStatus(data: JSONObject) {
        val processing = data.optBoolean("isProcessing", false)
        val speaking = data.optBoolean("isDigitalHumanSpeaking", false)
        val completed = data.optBoolean("isCompleted", false) ||
            data.optString("status").equals("completed", ignoreCase = true)
        _isProcessing.value = processing
        _isDigitalHumanSpeaking.value = speaking
        if (completed) {
            markInterviewCompleted("status-event")
        }
    }

    private fun handleError(payload: Any?) {
        val message = when (payload) {
            is JSONObject -> payload.optString("message")
            is String -> payload
            else -> payload?.toString()
        } ?: "æœªçŸ¥é”™è¯¯"
        _errors.tryEmit(message)
    }

    private fun markInterviewCompleted(reason: String? = null) {
        if (_interviewCompleted.value) return
        Log.i(TAG, "æ ‡è®°é¢è¯•å·²å®Œæˆ${reason?.let { "ï¼š$it" } ?: ""}")
        _interviewCompleted.value = true
        stopRecordingInternal()
    }

    private fun playClientSideTts(text: String, textHash: String?) {
        Log.d(TAG, "playClientSideTtsè¢«è°ƒç”¨ - text=$text, textHash=$textHash")
        
        if (text.isBlank()) {
            Log.w(TAG, "TTSæ–‡æœ¬ä¸ºç©ºï¼Œå–æ¶ˆæ’­æ”¾")
            currentPlayingTextHash = null
            return
        }
        
        scope.launch {
            try {
                Log.i(TAG, "å¼€å§‹è°ƒç”¨é˜¿é‡Œäº‘TTS - textLen=${text.length}, textHash=$textHash")
                val audioFile = aliyunSpeechService.synthesizeSpeech(text)
                Log.i(TAG, "TTSæˆåŠŸï¼Œå¼€å§‹æ’­æ”¾ - file=${audioFile.absolutePath}, textHash=$textHash")
                playAudioFromPath(audioFile.absolutePath, textHash, text)
            } catch (e: Exception) {
                Log.e(TAG, "å®¢æˆ·ç«¯TTSå¤±è´¥", e)
                _errors.tryEmit(e.message ?: "è¯­éŸ³æ’­æ”¾å¤±è´¥")
                // TTSå¤±è´¥æ—¶æ¸…é™¤æ’­æ”¾æ ‡è®°
                currentPlayingTextHash = null
            }
        }
    }

    private fun playAudioFromPath(path: String, textHash: String?, digitalHumanText: String?) {
        scope.launch {
            playPreparedAudio(path, textHash, digitalHumanText)
        }
    }
    
    private fun playAudioFromUrl(url: String, textHash: String?, digitalHumanText: String?) {
        scope.launch {
            val downloaded = downloadAudioToCache(url)
            if (downloaded != null) {
                playPreparedAudio(downloaded.absolutePath, textHash, digitalHumanText)
            } else {
                Log.e(TAG, "ä¸‹è½½è¿œç¨‹éŸ³é¢‘å¤±è´¥ï¼Œæ— æ³•æ’­æ”¾ - url=$url")
                currentPlayingTextHash = null
            }
        }
    }

    private suspend fun playPreparedAudio(path: String, textHash: String?, digitalHumanText: String?) {
        val preparedPath = preparePlayableAudio(path)
        if (preparedPath == null) {
            Log.e(TAG, "éŸ³é¢‘é¢„å¤„ç†å¤±è´¥ï¼Œæ— æ³•æ’­æ”¾ - path=$path")
            currentPlayingTextHash = null
            return
        }

        Log.d(TAG, "playPreparedAudio - preparedPath=$preparedPath, textHash=$textHash")

        // å°†å¯æ’­æ”¾è·¯å¾„åŒæ­¥ç»™æ•°å­—äºº
        duixAudioSink?.invoke(preparedPath)

        try {
            // å¦‚æœæ­£åœ¨æ’­æ”¾ç›¸åŒçš„æ–‡æœ¬ï¼Œè·³è¿‡
            if (textHash != null && currentPlayingTextHash == textHash && _isDigitalHumanSpeaking.value) {
                Log.w(TAG, "âš ï¸ æ£€æµ‹åˆ°é‡å¤æ’­æ”¾è¯·æ±‚ï¼ˆæ­£åœ¨æ’­æ”¾ä¸­ï¼‰ï¼Œè·³è¿‡ - textHash=$textHash, path=$preparedPath")
                return
            }
            
            mediaPlayer?.release()
            releaseVisualizer() // å…ˆé‡Šæ”¾æ—§çš„Visualizer
            
            mediaPlayer = MediaPlayer().apply {
                setDataSource(preparedPath)
                
                setOnPreparedListener {
                    val sessionId = audioSessionId
                    Log.i(TAG, "MediaPlayerå‡†å¤‡å®Œæˆ - audioSessionId=$sessionId, textHash=$textHash")
                    
                    if (sessionId == 0) {
                        Log.e(TAG, "è­¦å‘Šï¼šaudioSessionIdä¸º0ï¼Œæ— æ³•åˆå§‹åŒ–Visualizer")
                    }
                    
                    start()
                    Log.i(TAG, "MediaPlayerå¼€å§‹æ’­æ”¾ - textHash=$textHash")
                    this@RealtimeVoiceManager._isDigitalHumanSpeaking.value = true
                    digitalHumanController?.onTtsPlayback(preparedPath, digitalHumanText)
                    
                    // å»¶è¿Ÿä¸€å°æ®µæ—¶é—´ç¡®ä¿æ’­æ”¾çœŸæ­£å¼€å§‹åå†åˆå§‹åŒ–Visualizer
                    scope.launch {
                        delay(100) // ç­‰å¾…100msç¡®ä¿æ’­æ”¾å·²å¼€å§‹
                        val finalSessionId = audioSessionId
                        Log.d(TAG, "å»¶è¿Ÿåçš„audioSessionId=$finalSessionId")
                        if (finalSessionId != 0) {
                            setupAudioVisualizer()
                        } else {
                            Log.e(TAG, "æ— æ³•åˆå§‹åŒ–Visualizerï¼šaudioSessionIdä»ä¸º0")
                        }
                    }
                }
                
                setOnCompletionListener {
                    Log.i(TAG, "MediaPlayeræ’­æ”¾å®Œæˆ - textHash=$textHash")
                    this@RealtimeVoiceManager._isDigitalHumanSpeaking.value = false
                    releaseVisualizer()
                    // é‡ç½®æ•°å­—äººå˜´å‹
                    digitalHumanController?.updateMouthOpenness(0f)
                    
                    // æ ‡è®°ä¸ºå·²æ’­æ”¾
                    if (textHash != null) {
                        playedTextHashes.add(textHash)
                        currentPlayingTextHash = null
                        Log.d(TAG, "æ–‡æœ¬æ’­æ”¾å®Œæˆï¼Œå·²æ ‡è®°ä¸ºå·²æ’­æ”¾ - textHash=$textHash, å·²æ’­æ”¾æ€»æ•°=${playedTextHashes.size}")
                    }
                    
                    // VADæ¨¡å¼ä¸‹è‡ªåŠ¨é‡æ–°å¼€å§‹å½•éŸ³ï¼Œå®ç°å®æ—¶äº’åŠ¨
                    if (!_interviewCompleted.value && vadEnabled && _connectionState.value == ConnectionState.CONNECTED) {
                        scope.launch {
                            delay(500) // çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…ç«‹å³å¼€å§‹å½•éŸ³
                            Log.i(TAG, "TTSæ’­æ”¾å®Œæˆï¼ŒVADæ¨¡å¼è‡ªåŠ¨é‡æ–°å¼€å§‹å½•éŸ³")
                            startRecording()
                        }
                    }
                }
                
                setOnErrorListener { mp, what, extra ->
                    Log.e(TAG, "MediaPlayeré”™è¯¯ - what=$what, extra=$extra, textHash=$textHash")
                    this@RealtimeVoiceManager._isDigitalHumanSpeaking.value = false
                    releaseVisualizer()
                    // å‡ºé”™æ—¶æ¸…é™¤æ’­æ”¾æ ‡è®°
                    currentPlayingTextHash = null
                    true
                }
                
                prepareAsync()
            }
        } catch (e: Exception) {
            Log.e(TAG, "æ’­æ”¾éŸ³é¢‘å¤±è´¥", e)
            _errors.tryEmit(e.message ?: "æ’­æ”¾éŸ³é¢‘å¤±è´¥")
        }
    }

    private fun setupAudioVisualizer(retryAttempts: Int = VISUALIZER_MAX_RETRY) {
        try {
            // å…ˆé‡Šæ”¾æ—§çš„Visualizer
            releaseVisualizer()
            
            val player = mediaPlayer
            if (player == null) {
                Log.e(TAG, "MediaPlayerä¸ºnullï¼Œæ— æ³•åˆå§‹åŒ–Visualizer")
                return
            }
            
            // ç¡®ä¿MediaPlayeræ­£åœ¨æ’­æ”¾
            if (!player.isPlaying) {
                Log.w(TAG, "MediaPlayeræœªåœ¨æ’­æ”¾ï¼Œå»¶è¿Ÿåˆå§‹åŒ–Visualizerï¼ˆå‰©ä½™é‡è¯•=$retryAttemptsï¼‰")
                scheduleVisualizerRetry("MediaPlayeræœªåœ¨æ’­æ”¾", retryAttempts)
                return
            }
            
            val audioSessionId = player.audioSessionId
            if (audioSessionId == 0) {
                Log.w(TAG, "æ— æ•ˆçš„audioSessionId: $audioSessionIdï¼ŒMediaPlayerå¯èƒ½æœªæ­£ç¡®åˆå§‹åŒ–ï¼ˆå‰©ä½™é‡è¯•=$retryAttemptsï¼‰")
                scheduleVisualizerRetry("audioSessionIdä¸º0", retryAttempts)
                return
            }
            
            Log.d(TAG, "å¼€å§‹è®¾ç½®éŸ³é¢‘å¯è§†åŒ– - audioSessionId=$audioSessionId, isPlaying=${player.isPlaying}")
            
            // åˆ›å»ºVisualizerå®ä¾‹
            val newVisualizer = Visualizer(audioSessionId)
            Log.d(TAG, "Visualizerå®ä¾‹å·²åˆ›å»º")
            
            // é…ç½®captureSize
            val captureSizeRange = Visualizer.getCaptureSizeRange()
            val targetSize = captureSizeRange[0].coerceAtLeast(256) // è‡³å°‘256å­—èŠ‚
            newVisualizer.captureSize = targetSize
            val setSizeResult = newVisualizer.captureSize
            Log.d(TAG, "Visualizeré…ç½® - captureSize=$targetSize (è®¾ç½®ç»“æœ=$setSizeResult), range=${captureSizeRange[0]}-${captureSizeRange[1]}")
            
            // è®¾ç½®æ•°æ®æ•è·ç›‘å¬å™¨
            val captureRate = Visualizer.getMaxCaptureRate()
            Log.d(TAG, "è®¾ç½®æ•°æ®æ•è·ç›‘å¬å™¨ - captureRate=$captureRate")
            
            newVisualizer.setDataCaptureListener(
                object : Visualizer.OnDataCaptureListener {
                    override fun onWaveFormDataCapture(
                        visualizer: Visualizer?,
                        waveform: ByteArray?,
                        samplingRate: Int
                    ) {
                        if (waveform != null && waveform.isNotEmpty()) {
                            updateDigitalHumanMouth(waveform)
                        }
                    }

                    override fun onFftDataCapture(
                        visualizer: Visualizer?,
                        fft: ByteArray?,
                        samplingRate: Int
                    ) {
                        // å¯ç”¨äºé¢‘è°±åˆ†æ
                    }
                },
                captureRate,  // ä½¿ç”¨æœ€å¿«æ›´æ–°ç‡
                true,   // æ•è·æ³¢å½¢æ•°æ®
                false   // ä¸æ•è·FFTæ•°æ®ï¼ˆæš‚ä¸éœ€è¦ï¼‰
            )
            Log.d(TAG, "æ•°æ®æ•è·ç›‘å¬å™¨å·²è®¾ç½®")
            
            // å¯ç”¨Visualizer
            newVisualizer.enabled = true
            val enableResult = newVisualizer.enabled
            Log.d(TAG, "å°è¯•å¯ç”¨Visualizer - enabledè®¾ç½®ç»“æœ=$enableResult")
            
            // éªŒè¯å¯ç”¨çŠ¶æ€
            val isEnabled = newVisualizer.enabled
            Log.d(TAG, "Visualizerå¯ç”¨çŠ¶æ€æ£€æŸ¥ - enabled=$isEnabled, captureSize=${newVisualizer.captureSize}")
            
            if (isEnabled) {
                visualizer = newVisualizer
                Log.i(TAG, "âœ… Visualizerå·²æˆåŠŸå¯åŠ¨å¹¶å¯ç”¨ - captureRate=$captureRate, captureSize=${newVisualizer.captureSize}")
                Log.i(TAG, "âœ… VisualizeréªŒè¯é€šè¿‡ï¼Œæ•°å­—äººå˜´å‹é©±åŠ¨å·²å°±ç»ªï¼Œç­‰å¾…æ³¢å½¢æ•°æ®...")
                
                // å»¶è¿Ÿä¸€å°æ®µæ—¶é—´åæµ‹è¯•æ˜¯å¦æ”¶åˆ°æ•°æ®
                scope.launch {
                    delay(500)
                    if (visualizer?.enabled == true) {
                        Log.i(TAG, "âœ… Visualizerè¿è¡Œæ­£å¸¸ï¼Œåº”è¯¥å¼€å§‹æ¥æ”¶æ³¢å½¢æ•°æ®")
                    } else {
                        Log.e(TAG, "âŒ Visualizeråœ¨500msåè¢«ç¦ç”¨ï¼Œå¯èƒ½æœ‰é—®é¢˜")
                    }
                }
            } else {
                Log.e(TAG, "âŒ Visualizerå¯ç”¨å¤±è´¥ - enabledä»ä¸ºfalse")
                try {
                    newVisualizer.release()
                } catch (e: Exception) {
                    Log.e(TAG, "é‡Šæ”¾Visualizerå¤±è´¥", e)
                }
                visualizer = null
            }
            
        } catch (e: SecurityException) {
            Log.e(TAG, "âŒ è®¾ç½®éŸ³é¢‘å¯è§†åŒ–å¤±è´¥ï¼šç¼ºå°‘MODIFY_AUDIO_SETTINGSæƒé™", e)
            _errors.tryEmit("éŸ³é¢‘å¯è§†åŒ–éœ€è¦MODIFY_AUDIO_SETTINGSæƒé™")
        } catch (e: IllegalStateException) {
            Log.e(TAG, "âŒ è®¾ç½®éŸ³é¢‘å¯è§†åŒ–å¤±è´¥ï¼šMediaPlayerçŠ¶æ€å¼‚å¸¸", e)
            _errors.tryEmit("éŸ³é¢‘å¯è§†åŒ–åˆå§‹åŒ–å¤±è´¥ï¼ˆçŠ¶æ€å¼‚å¸¸ï¼‰")
        } catch (e: RuntimeException) {
            Log.e(TAG, "âŒ è®¾ç½®éŸ³é¢‘å¯è§†åŒ–å¤±è´¥ï¼šè¿è¡Œæ—¶é”™è¯¯", e)
            _errors.tryEmit("éŸ³é¢‘å¯è§†åŒ–åˆå§‹åŒ–å¤±è´¥")
        } catch (e: Exception) {
            Log.e(TAG, "âŒ è®¾ç½®éŸ³é¢‘å¯è§†åŒ–å¤±è´¥ï¼šæœªçŸ¥é”™è¯¯", e)
            _errors.tryEmit("éŸ³é¢‘å¯è§†åŒ–åˆå§‹åŒ–å¤±è´¥")
        }
    }

    private var lastMouthUpdate = 0L
    private var mouthUpdateCount = 0
    
    private fun updateDigitalHumanMouth(waveform: ByteArray) {
        if (waveform.isEmpty()) {
            if (mouthUpdateCount == 0) {
                Log.w(TAG, "æ”¶åˆ°ç©ºçš„æ³¢å½¢æ•°æ®")
            }
            return
        }
        
        try {
            // Visualizeræ³¢å½¢æ•°æ®æ˜¯8ä½æ— ç¬¦å·ï¼ˆ0-255ï¼‰ï¼Œä¸­å¿ƒç‚¹åœ¨128
            var sum = 0f
            for (i in waveform.indices) {
                val sample = (waveform[i].toInt() and 0xFF) - 128  // è½¬æ¢ä¸º-128åˆ°127
                val normalized = sample / 128f
                sum += normalized * normalized
            }
            
            val rms = sqrt(sum / waveform.size)
            // ä½¿ç”¨æ›´åˆç†çš„æ˜ å°„ï¼šå°†RMSå€¼æ˜ å°„åˆ°0-1èŒƒå›´ï¼Œå¹¶æ·»åŠ å¹³æ»‘å¤„ç†
            // RMSé€šå¸¸åœ¨0-0.3ä¹‹é—´ï¼Œæˆ‘ä»¬å°†å…¶æ˜ å°„åˆ°0-0.8çš„å˜´å‹èŒƒå›´
            val mouthOpenness = (rms * 3f).coerceIn(0f, 0.8f)  // è°ƒæ•´æ”¾å¤§å€æ•°ï¼Œé¿å…è¿‡åº¦å¼€å£
            
            // æ›´æ–°æ•°å­—äººå˜´å‹
            val controller = digitalHumanController
            if (controller != null) {
                controller.updateMouthOpenness(mouthOpenness)
                
                mouthUpdateCount++
                val now = System.currentTimeMillis()
                
                // ç¬¬ä¸€æ¬¡æ›´æ–°æ—¶æ‰“å°è¯¦ç»†ä¿¡æ¯
                if (mouthUpdateCount == 1) {
                    Log.i(TAG, "ğŸ‰ æ•°å­—äººå˜´å‹é¦–æ¬¡æ›´æ–° - rms=$rms, mouthOpenness=$mouthOpenness, waveformSize=${waveform.size}")
                    lastMouthUpdate = now
                } else if (now - lastMouthUpdate > 1000) {
                    // ä¹‹åæ¯ç§’æ‰“å°ä¸€æ¬¡
                    Log.d(TAG, "æ•°å­—äººå˜´å‹æ›´æ–° #$mouthUpdateCount - rms=$rms, mouthOpenness=$mouthOpenness, waveformSize=${waveform.size}")
                    lastMouthUpdate = now
                }
            } else {
                if (mouthUpdateCount == 0) {
                    Log.w(TAG, "âš ï¸ DigitalHumanControlleræœªè®¾ç½®ï¼Œæ— æ³•é©±åŠ¨å˜´å‹ï¼ˆä½†Visualizeræ­£åœ¨å·¥ä½œï¼‰")
                    mouthUpdateCount++  // åªè­¦å‘Šä¸€æ¬¡
                } else if (mouthUpdateCount % 100 == 0) {
                    // æ¯100æ¬¡æ›´æ–°æé†’ä¸€æ¬¡
                    Log.w(TAG, "âš ï¸ DigitalHumanControllerä»æœªè®¾ç½®ï¼Œå·²æ›´æ–°${mouthUpdateCount}æ¬¡ä½†æ— æ³•é©±åŠ¨å˜´å‹")
                }
            }
        } catch (e: Exception) {
            Log.e(TAG, "âŒ æ›´æ–°æ•°å­—äººå˜´å‹å¤±è´¥", e)
        }
    }

    private fun appendMessage(message: ConversationMessage) {
        _conversation.update { previous -> previous + message }
    }

    private fun releaseVisualizer() {
        try {
            visualizer?.release()
        } catch (_: Exception) {
        }
        visualizer = null
    }

    private fun scheduleVisualizerRetry(reason: String, remainingAttempts: Int) {
        if (remainingAttempts <= 0) {
            Log.e(TAG, "Visualizeråˆå§‹åŒ–å¤±è´¥ï¼Œæ”¾å¼ƒï¼š$reason")
            return
        }
        scope.launch {
            delay(VISUALIZER_RETRY_DELAY_MS)
            Log.d(TAG, "é‡æ–°å°è¯•åˆå§‹åŒ–Visualizerï¼ˆå‰©ä½™${remainingAttempts - 1}æ¬¡ï¼‰ - åŸå› ï¼š$reason")
            setupAudioVisualizer(remainingAttempts - 1)
        }
    }

    private fun stopRecordingInternal() {
        try {
            audioRecord?.stop()
        } catch (_: Exception) {
        }
        try {
            audioRecord?.release()
        } catch (_: Exception) {
        }
        audioRecord = null
        isRecording = false
        _isRecordingFlow.value = false
    }

    private fun joinSession(sessionId: String, userId: String?, jobPosition: String?, background: String?) {
        val payload = JSONObject().apply {
            put("sessionId", sessionId)
            userId?.let { put("userId", it) }
            jobPosition?.let { put("jobPosition", it) }
            background?.let { put("background", it) }
        }
        socket?.emit("join_session", payload)
    }

    fun submitUserText(text: String) {
        Log.d(TAG, "submitUserTextè¢«è°ƒç”¨ - text=$text")
        
        val normalized = text.trim()
        if (normalized.isEmpty()) {
            Log.w(TAG, "æ–‡æœ¬ä¸ºç©ºï¼Œå–æ¶ˆæäº¤")
            _isProcessing.value = false
            return
        }
        
        val sessionId = currentSessionId
        if (sessionId.isNullOrBlank()) {
            Log.e(TAG, "ä¼šè¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•æäº¤æ–‡æœ¬")
            _errors.tryEmit("ä¼šè¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•æäº¤æ–‡æœ¬")
            _isProcessing.value = false
            return
        }
        
        if (socket == null || !socket!!.connected()) {
            Log.e(TAG, "WebSocketæœªè¿æ¥ï¼Œæ— æ³•æäº¤æ–‡æœ¬")
            _errors.tryEmit("WebSocketæœªè¿æ¥")
            _isProcessing.value = false
            return
        }
        
        appendMessage(ConversationMessage(role = ConversationRole.USER, text = normalized))
        
        val payload = JSONObject().apply {
            put("text", normalized)
            put("sessionId", sessionId)
            currentUserId?.let { put("userId", it) }
            currentJobPosition?.let { put("jobPosition", it) }
            currentBackground?.let { put("background", it) }
        }
        
        Log.i(TAG, "é€šè¿‡WebSocketå‘é€text_message - sessionId=$sessionId, text=$normalized")
        socket?.emit("text_message", payload)
        _isProcessing.value = true
    }
}
