# 🤖 数字人实时语音沟通测试完整指南

> **STAR-LINK AI 数字人面试系统 v1.0**  
> 完整的端到端测试指南 - 从环境配置到实际测试

---

## 📋 目录

- [系统概述](#系统概述)
- [快速开始](#快速开始)
- [环境配置](#环境配置)
- [测试方式](#测试方式)
  - [方式一：Web 端测试（推荐）](#方式一web-端测试推荐)
  - [方式二：Android 端测试](#方式二android-端测试)
- [常见问题](#常见问题)
- [故障排查](#故障排查)
- [技术架构](#技术架构)

---

## 🌟 系统概述

### 核心功能

本系统实现了完整的实时语音交互数字人：

✅ **实时语音识别 (ASR)** - 火山引擎/声网 ASR 服务  
✅ **大语言模型 (LLM)** - DeepSeek AI 智能对话  
✅ **语音合成 (TTS)** - 阿里云/Azure 高质量语音  
✅ **Live2D 数字人** - 实时口型同步和表情动画  
✅ **打断机制** - 支持用户随时打断数字人说话  
✅ **WebSocket 通信** - 低延迟实时双向通信

### 技术栈

```
┌─────────────────────────────────────────┐
│         Android App (Kotlin)            │
│  Live2D + WebSocket + MediaPlayer       │
└─────────────────────────────────────────┘
              ↕ WebSocket
┌─────────────────────────────────────────┐
│      Node.js Backend (TypeScript)       │
│  Socket.IO + Express + Prisma           │
└─────────────────────────────────────────┘
              ↕ HTTP/API
┌─────────────────────────────────────────┐
│         外部 AI 服务                     │
│  ASR + LLM + TTS                        │
└─────────────────────────────────────────┘
```

---

## 🚀 快速开始

### 一键启动（推荐）

```bash
# 1. 检查配置
./check-digital-human-config.sh

# 2. 启动系统
./start-digital-human-test.sh
```

启动成功后，系统会自动打开：
- 🌐 Web 测试页面: `http://localhost:3001/test/digital-human`
- 📊 Admin Dashboard: `http://localhost:5173`

### 手动启动

如果一键启动失败，可以手动启动各个服务：

```bash
# 终端 1: 启动后端
cd backend-api
npm run dev

# 终端 2: 启动前端（可选）
cd admin-dashboard
npm run dev
```

---

## ⚙️ 环境配置

### 1. 安装依赖

```bash
# 安装 Node.js (≥16.x)
# 访问 https://nodejs.org/ 下载安装

# 安装项目依赖
cd backend-api
npm install

cd ../admin-dashboard
npm install
```

### 2. 配置环境变量

创建 `backend-api/.env` 文件：

```bash
# ============= 核心配置 =============

# DeepSeek API (必需)
DEEPSEEK_API_KEY=your-deepseek-api-key
DEEPSEEK_BASE_URL=https://api.deepseek.com/v1

# ============= ASR 配置（选择一个）=============

# 方案 A: 火山引擎 ASR (推荐)
VOLC_APP_ID=your-volc-app-id
VOLC_ACCESS_KEY=your-volc-access-key
VOLC_SECRET_KEY=your-volc-secret-key

# 方案 B: 声网 ASR
AGORA_APP_ID=your-agora-app-id
AGORA_API_KEY=your-agora-api-key
AGORA_API_SECRET=your-agora-api-secret

# ============= TTS 配置（选择一个）=============

# 方案 A: 阿里云 TTS (推荐)
ALIYUN_ACCESS_KEY_ID=your-aliyun-access-key-id
ALIYUN_ACCESS_KEY_SECRET=your-aliyun-access-key-secret
ALIYUN_TTS_APP_KEY=your-aliyun-tts-app-key

# 方案 B: Azure TTS
AZURE_SPEECH_KEY=your-azure-speech-key
AZURE_SPEECH_REGION=your-azure-region

# ============= 数据库（可选）=============
DATABASE_URL="postgresql://user:password@localhost:5432/ai_interview"

# ============= 阿里云 OSS（可选）=============
ALIYUN_OSS_REGION=oss-cn-beijing
ALIYUN_OSS_BUCKET=your-bucket-name
```

### 3. 获取 API 密钥

#### DeepSeek API
1. 访问 [DeepSeek 控制台](https://platform.deepseek.com/)
2. 注册并创建 API Key
3. 复制 API Key 到 `.env` 文件

#### 火山引擎 ASR
1. 访问 [火山引擎控制台](https://console.volcengine.com/)
2. 开通"语音识别"服务
3. 创建应用并获取 App ID 和密钥

#### 阿里云 TTS
1. 访问 [阿里云控制台](https://home.console.aliyun.com/)
2. 开通"智能语音交互"服务
3. 创建项目并获取 Access Key

---

## 🧪 测试方式

### 方式一：Web 端测试（推荐）

**优点**: 快速、直观、无需编译 Android 应用

#### 步骤

1. **启动系统**
   ```bash
   ./start-digital-human-test.sh
   ```

2. **打开测试页面**
   
   浏览器访问: `http://localhost:3001/test/digital-human`

3. **配置参数**
   
   - WebSocket 地址: `ws://localhost:3001` (默认)
   - 职位: `软件工程师` (或其他职位)
   - 用户 ID: `test-user`
   - 采样率: `16000 Hz`

4. **开始测试**
   
   a. 点击 **"🔌 连接服务"** 按钮
   
   b. 等待连接成功（状态变为"已连接"）
   
   c. 点击 **"🎤 开始录音"** 按钮
   
   d. 说话（例如："你好，我想应聘软件工程师"）
   
   e. 点击 **"⏹️ 停止录音"** 按钮
   
   f. 等待系统处理（ASR → LLM → TTS）
   
   g. 数字人会自动回复并播放语音

5. **查看交互**
   
   - 对话内容会实时显示在"对话面板"
   - 音频可视化会显示录音和播放状态
   - 处理状态会实时更新

#### 测试示例对话

| 轮次 | 你说 | 数字人回复 |
|------|------|-----------|
| 1 | "你好，我想应聘软件工程师" | "你好！很高兴认识你。请先做一个简单的自我介绍吧。" |
| 2 | "我叫张三，有5年Java开发经验" | "很好！能具体说说你最近参与的项目吗？" |
| 3 | "我参与了XX电商平台的后端开发" | "听起来很有经验。请问你在项目中负责哪些模块？" |

---

### 方式二：Android 端测试

**优点**: 完整体验，包含 Live2D 数字人动画

#### 步骤

1. **配置 Android 应用**
   
   编辑 `android-v0-compose/app/src/main/java/com/xlwl/AiMian/config/AppConfig.kt`:
   
   ```kotlin
   object AppConfig {
       // 修改为你的后端 IP 地址
       const val realtimeVoiceWsUrl = "ws://192.168.1.100:3001"
       
       // 其他配置...
   }
   ```
   
   **注意**: 
   - 不要使用 `localhost`，使用电脑的局域网 IP
   - 确保手机和电脑在同一局域网
   - 查看本机 IP: `ifconfig` (Mac/Linux) 或 `ipconfig` (Windows)

2. **编译并安装 Android 应用**
   
   ```bash
   cd android-v0-compose
   ./gradlew assembleDebug
   adb install -r app/build/outputs/apk/debug/app-debug.apk
   ```
   
   或在 Android Studio 中直接运行

3. **启动后端服务**
   
   ```bash
   ./start-digital-human-test.sh
   ```

4. **在手机上测试**
   
   a. 打开应用，进入"数字人面试"页面
   
   b. 授予麦克风和摄像头权限
   
   c. 等待"语音服务连接中…"变为"连接成功"
   
   d. 点击 **"开始答题"** 按钮
   
   e. 说话，系统会自动识别
   
   f. 数字人会回复，同时 Live2D 角色会同步口型
   
   g. 可以随时打断数字人说话

#### Android 测试界面说明

```
┌─────────────────────────────────────┐
│  [<]  问题计数 1/15                 │ ← 顶部导航
├─────────────────────────────────────┤
│                                     │
│      [Live2D 数字人全屏显示]        │ ← 主画面（可双击切换）
│                                     │
│            [你的摄像头小窗]          │ ← 可拖动位置
├─────────────────────────────────────┤
│  STAR-LINK 数字人正在聆听           │ ← 状态提示
│  ┌─────────────────────────────┐   │
│  │ 请您做一个简单的自我介绍     │   │ ← 面试问题
│  └─────────────────────────────┘   │
│                                     │
│  ┌─────────────────────────────┐   │
│  │ 🤖 STAR-LINK                │   │
│  │ 您好，请开始回答...         │   │ ← 对话内容
│  ├─────────────────────────────┤   │
│  │ 👤 我                        │   │
│  │ （正在聆听...）             │   │
│  └─────────────────────────────┘   │
│                                     │
│  [ 🎤 开始答题 ]                   │ ← 录音按钮
└─────────────────────────────────────┘
```

---

## ❓ 常见问题

### Q1: 连接失败，显示"WebSocket 连接超时"

**原因**: 后端服务未启动或网络不通

**解决方案**:
```bash
# 1. 检查后端是否运行
lsof -i :3001

# 2. 重启后端
./start-digital-human-test.sh

# 3. 检查防火墙是否允许 3001 端口
```

### Q2: 语音识别失败，提示"未识别到有效语音内容"

**原因**: 
- 录音时间太短
- 麦克风权限未授予
- 环境噪音过大
- ASR 服务配置错误

**解决方案**:
```bash
# 1. 检查麦克风权限
# 浏览器: 允许访问麦克风
# Android: 检查应用权限设置

# 2. 检查 ASR 配置
source backend-api/.env
echo $VOLC_APP_ID  # 或 $AGORA_APP_ID

# 3. 延长录音时间（至少 2-3 秒）

# 4. 查看后端日志
tail -f backend-api/digital-human-backend.log
```

### Q3: 数字人回复生成失败

**原因**: LLM API 调用失败

**解决方案**:
```bash
# 1. 检查 DeepSeek API Key
source backend-api/.env
echo $DEEPSEEK_API_KEY

# 2. 测试 API 连接
curl -X POST https://api.deepseek.com/v1/chat/completions \
  -H "Authorization: Bearer $DEEPSEEK_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"model":"deepseek-chat","messages":[{"role":"user","content":"你好"}]}'

# 3. 检查账户余额
# 登录 DeepSeek 控制台查看
```

### Q4: TTS 合成失败，无语音输出

**原因**: TTS 服务配置错误

**解决方案**:
```bash
# 1. 检查 TTS 配置
source backend-api/.env
echo $ALIYUN_ACCESS_KEY_ID  # 或 $AZURE_SPEECH_KEY

# 2. 测试 TTS 服务
# 查看后端日志中的 TTS 请求

# 3. 确认服务已开通
# 登录阿里云/Azure 控制台检查
```

### Q5: Android 应用无法连接到后端

**原因**: 
- IP 地址配置错误
- 手机和电脑不在同一网络
- 后端未启动

**解决方案**:
```bash
# 1. 查看本机 IP
ifconfig | grep inet  # Mac/Linux
ipconfig              # Windows

# 2. 确保手机和电脑在同一 WiFi

# 3. 修改 AppConfig.kt 中的 IP
# ws://你的IP:3001 (不是 localhost)

# 4. 重新编译安装应用
```

### Q6: Live2D 数字人不动或显示异常

**原因**: 
- Live2D 模型文件缺失
- 音频驱动未正确设置

**解决方案**:
```kotlin
// 检查 Live2D 初始化代码
// android-v0-compose/app/src/main/java/com/xlwl/AiMian/live2d/

// 确保音频驱动已正确连接
voiceManager.setLive2DController(live2DController)
```

---

## 🔧 故障排查

### 检查服务状态

```bash
# 1. 运行配置检查脚本
./check-digital-human-config.sh

# 2. 查看进程
ps aux | grep node

# 3. 查看端口占用
lsof -i :3001
lsof -i :5173

# 4. 查看实时日志
tail -f backend-api/digital-human-backend.log
```

### 查看详细日志

#### 后端日志
```bash
# 实时查看
tail -f backend-api/digital-human-backend.log

# 搜索错误
grep "ERROR" backend-api/digital-human-backend.log

# 搜索特定会话
grep "session-id-xxx" backend-api/digital-human-backend.log
```

#### Android 日志
```bash
# 查看应用日志
adb logcat | grep "RealtimeVoiceManager"
adb logcat | grep "Live2DView"
adb logcat | grep "DigitalInterview"
```

### 网络调试

```bash
# 测试 WebSocket 连接
wscat -c ws://localhost:3001

# 测试 HTTP API
curl http://localhost:3001/health

# 测试从手机访问
# 在手机浏览器访问: http://你的IP:3001/test/digital-human
```

### 重置系统

```bash
# 1. 停止所有服务
./stop-digital-human-test.sh

# 2. 清理端口
for port in 3000 3001 5173; do
  kill -9 $(lsof -ti:$port) 2>/dev/null || true
done

# 3. 重新安装依赖
cd backend-api
rm -rf node_modules
npm install

# 4. 重启系统
./start-digital-human-test.sh
```

---

## 🏗️ 技术架构

### 系统流程

```
1. 用户说话
   ↓
2. 麦克风采集音频 (Android/Web)
   ↓
3. WebSocket 发送音频数据 (Base64)
   ↓
4. 后端接收音频 (backend-api)
   ↓
5. ASR 识别语音 → 文本 (火山引擎/声网)
   ↓
6. LLM 生成回复 (DeepSeek)
   ↓
7. TTS 合成语音 (阿里云/Azure)
   ↓
8. 返回音频 URL
   ↓
9. 客户端播放音频
   ↓
10. Live2D 同步口型 (Android)
```

### 关键文件

#### 后端
```
backend-api/
├── src/
│   ├── index.ts                              # 主入口
│   ├── websocket/
│   │   └── realtime-voice.websocket.ts       # WebSocket 服务器
│   └── services/
│       ├── realtime-voice-pipeline.service.ts # 语音处理管道
│       ├── rtc-asr.service.ts                # ASR 服务
│       ├── ttsService.ts                     # TTS 服务
│       └── deepseekService.ts                # LLM 服务
└── public/
    └── test/
        └── digital-human.html                # Web 测试页面
```

#### Android
```
android-v0-compose/app/src/main/java/com/xlwl/AiMian/
├── ai/
│   ├── DigitalInterviewScreen.kt             # 数字人面试界面
│   └── realtime/
│       └── RealtimeVoiceManager.kt           # 语音管理器
├── live2d/
│   ├── Live2DView.kt                         # Live2D 视图
│   └── Live2DViewController.kt               # Live2D 控制器
└── config/
    └── AppConfig.kt                          # 应用配置
```

### WebSocket 事件

#### 客户端 → 服务器

| 事件名 | 参数 | 说明 |
|--------|------|------|
| `init_session` | `{sessionId, userId, jobPosition}` | 初始化会话 |
| `audio_data` | `{audio, sessionId, sampleRate, isFinal}` | 发送音频数据 |
| `interrupt` | `{sessionId}` | 打断数字人说话 |
| `disconnect` | - | 断开连接 |

#### 服务器 → 客户端

| 事件名 | 参数 | 说明 |
|--------|------|------|
| `connect` | - | 连接成功 |
| `voice_response` | `{audioUrl, text, sessionId, duration}` | 语音回复 |
| `audio_partial_result` | `{text, sessionId}` | 临时识别结果 |
| `error` | `{message, sessionId}` | 错误信息 |
| `disconnect` | - | 连接断开 |

---

## 📊 性能指标

### 延迟目标

| 环节 | 目标延迟 | 说明 |
|------|----------|------|
| 音频采集 | < 50ms | 实时音频捕获 |
| WebSocket 传输 | < 100ms | 网络传输延迟 |
| ASR 识别 | < 500ms | 语音转文字 |
| LLM 生成 | < 2s | 生成回复内容 |
| TTS 合成 | < 1s | 文字转语音 |
| **总延迟** | **< 4s** | 端到端响应时间 |

### 优化建议

1. **使用流式 TTS**: 边生成边播放，减少等待时间
2. **音频预加载**: 提前缓存常用回复
3. **并行处理**: ASR 和 VAD 并行执行
4. **本地 VAD**: 减少网络传输
5. **CDN 加速**: TTS 音频使用 CDN

---

## 📝 开发指南

### 添加新的面试问题

编辑 `backend-api/src/services/deepseekService.ts`:

```typescript
const systemPrompt = `
你是一位专业的面试官，负责${context.jobPosition}职位的面试。

面试流程:
1. 请候选人自我介绍
2. 询问工作经历和项目经验
3. 技术问题（3-5个）
4. 行为问题（2-3个）
5. 候选人提问
6. 总结

注意事项:
- 语气专业但友好
- 根据回答追问细节
- 每次只问一个问题
`;
```

### 自定义数字人形象

修改 Live2D 模型:

```kotlin
// Live2DViewController.kt
fun loadModel(modelPath: String) {
    // 加载自定义 Live2D 模型
    // 支持 .moc3 格式
}
```

### 添加新的 TTS 提供商

```typescript
// ttsService.ts
class CustomTTSService implements TTSProvider {
    async textToSpeech(params: {
        text: string;
        sessionId: string;
    }): Promise<TTSResult> {
        // 实现自定义 TTS 逻辑
    }
}
```

---

## 🎯 下一步

### 功能扩展

- [ ] 多轮对话上下文管理
- [ ] 表情识别和反馈
- [ ] 情感分析和评分
- [ ] 面试报告生成
- [ ] 多语言支持

### 性能优化

- [ ] 流式 TTS 输出
- [ ] 音频压缩
- [ ] WebRTC 替代 WebSocket
- [ ] 本地 VAD 检测
- [ ] 离线模式支持

### 部署优化

- [ ] Docker 容器化
- [ ] Kubernetes 编排
- [ ] 负载均衡
- [ ] 监控和日志
- [ ] CI/CD 自动化

---

## 📞 支持与反馈

### 获取帮助

- 📧 Email: support@star-link.ai
- 💬 Discord: [加入社区](https://discord.gg/star-link)
- 📖 文档: [在线文档](https://docs.star-link.ai)

### 报告问题

在 GitHub 上提交 Issue:
```
标题: [Bug] 简短描述问题
内容:
- 问题描述
- 复现步骤
- 期望行为
- 实际行为
- 环境信息
- 日志截图
```

---

## 📄 许可证

本项目采用 MIT 许可证。详见 [LICENSE](LICENSE) 文件。

---

**🎉 祝测试顺利！如有问题请参考上述指南或联系技术支持。**

---

*最后更新: 2024年11月*  
*版本: v1.0.0*

