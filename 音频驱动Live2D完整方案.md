# ç¬¬ä¸‰æ–¹APIéŸ³é¢‘é©±åŠ¨Live2Då®Œæ•´æ–¹æ¡ˆ

## ğŸ¯ æ ¸å¿ƒé—®é¢˜

**ç¬¬ä¸‰æ–¹APIè¿”å›çš„éŸ³é¢‘èƒ½å¦ç›´æ¥é©±åŠ¨Live2Dï¼Ÿ**

**ç­”æ¡ˆ**ï¼š**å¯ä»¥**ï¼Œä½†éœ€è¦**éŸ³é¢‘åˆ†æå’Œå¤„ç†**ã€‚

---

## ğŸ“Š éŸ³é¢‘æµç¨‹

```
ç¬¬ä¸‰æ–¹APIè¿”å›éŸ³é¢‘
    â†“
æ¥æ”¶éŸ³é¢‘æµï¼ˆPCM/WAV/MP3ï¼‰
    â†“
éŸ³é¢‘è§£ç ï¼ˆè½¬æ¢ä¸ºPCMæ ¼å¼ï¼‰
    â†“
å®æ—¶éŸ³é¢‘åˆ†æï¼ˆFFTé¢‘è°±åˆ†æï¼‰
    â†“
æå–éŸ³é¢‘ç‰¹å¾ï¼ˆéŸ³é‡ã€é¢‘è°±ï¼‰
    â†“
æ˜ å°„åˆ°Live2Då‚æ•°ï¼ˆå˜´å‹ã€è¡¨æƒ…ï¼‰
    â†“
Live2DåŠ¨ç”»æ›´æ–°
```

---

## ğŸ”§ å®ç°æ–¹æ¡ˆ

### æ–¹æ¡ˆä¸€ï¼šAndroidç«¯å®æ—¶éŸ³é¢‘åˆ†æï¼ˆæ¨èï¼‰

#### 1. æ¥æ”¶éŸ³é¢‘æµ

```kotlin
// AudioStreamReceiver.kt
class AudioStreamReceiver {
    private var audioTrack: AudioTrack? = null
    private var isPlaying = false
    
    fun startReceivingAudio(audioUrl: String) {
        // ä»URLæˆ–WebRTCæµæ¥æ”¶éŸ³é¢‘
        val audioStream = fetchAudioStream(audioUrl)
        
        // é…ç½®AudioTrack
        val sampleRate = 44100
        val channelConfig = AudioFormat.CHANNEL_OUT_MONO
        val audioFormat = AudioFormat.ENCODING_PCM_16BIT
        
        val bufferSize = AudioTrack.getMinBufferSize(
            sampleRate,
            channelConfig,
            audioFormat
        ) * 2
        
        audioTrack = AudioTrack(
            AudioManager.STREAM_MUSIC,
            sampleRate,
            channelConfig,
            audioFormat,
            bufferSize,
            AudioTrack.MODE_STREAM
        )
        
        audioTrack?.play()
        isPlaying = true
        
        // åœ¨åå°çº¿ç¨‹å¤„ç†éŸ³é¢‘æµ
        processAudioStream(audioStream)
    }
    
    private fun processAudioStream(stream: InputStream) {
        val buffer = ByteArray(4096)
        
        while (isPlaying) {
            val bytesRead = stream.read(buffer)
            if (bytesRead > 0) {
                // æ’­æ”¾éŸ³é¢‘
                audioTrack?.write(buffer, 0, bytesRead)
                
                // åŒæ—¶åˆ†æéŸ³é¢‘é©±åŠ¨Live2D
                analyzeAudioForLive2D(buffer)
            }
        }
    }
}
```

#### 2. éŸ³é¢‘åˆ†æï¼ˆFFTé¢‘è°±åˆ†æï¼‰

```kotlin
// AudioAnalyzer.kt
import android.media.audiofx.Visualizer
import kotlin.math.*

class AudioAnalyzer {
    private var visualizer: Visualizer? = null
    private var fftSize = 512
    private var sampleRate = 44100
    
    fun analyzeAudio(audioData: ByteArray): Float {
        // å°†å­—èŠ‚æ•°ç»„è½¬æ¢ä¸ºæµ®ç‚¹æ•°æ•°ç»„
        val audioSamples = audioData.map { it.toFloat() / 128f }
        
        // è®¡ç®—éŸ³é‡ï¼ˆRMSï¼‰
        val volume = calculateRMS(audioSamples)
        
        // FFTé¢‘è°±åˆ†æï¼ˆç”¨äºæ£€æµ‹éŸ³è°ƒï¼‰
        val spectrum = performFFT(audioSamples)
        
        // æå–ç‰¹å¾
        val mouthOpenness = mapVolumeToMouthOpenness(volume)
        val pitch = extractPitch(spectrum)
        
        return mouthOpenness
    }
    
    private fun calculateRMS(samples: List<Float>): Float {
        var sum = 0f
        for (sample in samples) {
            sum += sample * sample
        }
        return sqrt(sum / samples.size)
    }
    
    private fun mapVolumeToMouthOpenness(volume: Float): Float {
        // å°†éŸ³é‡æ˜ å°„åˆ°0.0-1.0çš„å˜´å‹å¼€æ”¾åº¦
        // 0.0 = é—­å˜´ï¼Œ1.0 = æœ€å¤§å¼€å£
        return (volume * 2f).coerceIn(0f, 1f)
    }
    
    private fun performFFT(samples: List<Float>): FloatArray {
        // ç®€åŒ–çš„FFTå®ç°ï¼ˆå®é™…åº”ä½¿ç”¨FFTåº“ï¼‰
        // è¿™é‡Œä½¿ç”¨Androidçš„Visualizer APIä¼šæ›´ç®€å•
        return FloatArray(fftSize)
    }
    
    private fun extractPitch(spectrum: FloatArray): Float {
        // æå–åŸºé¢‘ï¼ˆéŸ³è°ƒï¼‰
        // å¯ä»¥ç”¨å³°å€¼æ£€æµ‹ç®—æ³•
        var maxIndex = 0
        var maxValue = 0f
        
        for (i in spectrum.indices) {
            if (spectrum[i] > maxValue) {
                maxValue = spectrum[i]
                maxIndex = i
            }
        }
        
        // è½¬æ¢ä¸ºé¢‘ç‡
        return maxIndex * sampleRate / fftSize
    }
}
```

#### 3. ä½¿ç”¨Android Visualizer APIï¼ˆæ›´ç®€å•ï¼‰

```kotlin
// Live2DAudioDriver.kt
import android.media.audiofx.Visualizer
import android.media.MediaPlayer

class Live2DAudioDriver {
    private var visualizer: Visualizer? = null
    private var mediaPlayer: MediaPlayer? = null
    private var onMouthUpdate: ((Float) -> Unit)? = null
    
    fun setupAudioVisualizer(audioUrl: String) {
        mediaPlayer = MediaPlayer().apply {
            setDataSource(audioUrl)
            prepare()
        }
        
        // åˆ›å»ºVisualizerè¿æ¥åˆ°MediaPlayer
        val audioSessionId = mediaPlayer?.audioSessionId ?: 0
        
        visualizer = Visualizer(audioSessionId).apply {
            captureSize = Visualizer.getCaptureSizeRange()[1] // æœ€å¤§é‡‡æ ·
            setDataCaptureListener(object : Visualizer.OnDataCaptureListener {
                override fun onWaveFormDataCapture(
                    visualizer: Visualizer,
                    waveform: ByteArray,
                    samplingRate: Int
                ) {
                    // æ³¢å½¢æ•°æ®ï¼ˆç”¨äºéŸ³é‡æ£€æµ‹ï¼‰
                    val volume = calculateVolume(waveform)
                    onMouthUpdate?.invoke(volume)
                }
                
                override fun onFftDataCapture(
                    visualizer: Visualizer,
                    fft: ByteArray,
                    samplingRate: Int
                ) {
                    // FFTæ•°æ®ï¼ˆç”¨äºé¢‘è°±åˆ†æï¼‰
                    val pitch = extractPitch(fft)
                    // å¯ä»¥æ ¹æ®éŸ³è°ƒè°ƒæ•´è¡¨æƒ…
                }
            }, Visualizer.getMaxCaptureRate() / 2, true, true)
            
            enabled = true
        }
        
        mediaPlayer?.start()
    }
    
    private fun calculateVolume(waveform: ByteArray): Float {
        var sum = 0f
        for (i in waveform.indices step 2) {
            val sample = (waveform[i].toInt() shl 8) or waveform[i + 1].toInt()
            val normalized = sample / 32768f
            sum += normalized * normalized
        }
        val rms = sqrt(sum / (waveform.size / 2))
        
        // æ˜ å°„åˆ°0.0-1.0
        return (rms * 3f).coerceIn(0f, 1f)
    }
    
    private fun extractPitch(fft: ByteArray): Float {
        // æå–åŸºé¢‘
        var maxMagnitude = 0f
        var maxIndex = 0
        
        for (i in 0 until fft.size / 2) {
            val real = fft[i * 2].toFloat()
            val imaginary = fft[i * 2 + 1].toFloat()
            val magnitude = sqrt(real * real + imaginary * imaginary)
            
            if (magnitude > maxMagnitude) {
                maxMagnitude = magnitude
                maxIndex = i
            }
        }
        
        // è½¬æ¢ä¸ºé¢‘ç‡ï¼ˆHzï¼‰
        return maxIndex * 44100f / fft.size
    }
    
    fun setOnMouthUpdateListener(listener: (Float) -> Unit) {
        onMouthUpdate = listener
    }
    
    fun release() {
        visualizer?.release()
        mediaPlayer?.release()
    }
}
```

#### 4. é©±åŠ¨Live2D

```kotlin
// DigitalInterviewScreen.ktï¼ˆä¿®æ”¹ç‰ˆï¼‰
@Composable
fun DigitalInterviewScreen(
    uiState: DigitalInterviewUiState,
    onBackClick: () -> Unit
) {
    val context = LocalContext.current
    val live2DController = remember { Live2DViewController() }
    val audioDriver = remember { Live2DAudioDriver() }
    
    LaunchedEffect(Unit) {
        // è®¾ç½®éŸ³é¢‘é©±åŠ¨å›è°ƒ
        audioDriver.setOnMouthUpdateListener { mouthOpenness ->
            // æ›´æ–°Live2Då˜´å‹å‚æ•°
            live2DController.updateMouthOpenness(mouthOpenness)
        }
    }
    
    // å½“æ”¶åˆ°éŸ³é¢‘URLæ—¶
    LaunchedEffect(uiState.currentAudioUrl) {
        uiState.currentAudioUrl?.let { audioUrl ->
            // è®¾ç½®éŸ³é¢‘å¹¶å¼€å§‹åˆ†æ
            audioDriver.setupAudioVisualizer(audioUrl)
        }
    }
    
    Box(modifier = Modifier.fillMaxSize()) {
        // Live2Dè§†å›¾
        Live2DView(
            controller = live2DController,
            modifier = Modifier.align(Alignment.TopEnd)
        )
    }
    
    DisposableEffect(Unit) {
        onDispose {
            audioDriver.release()
        }
    }
}
```

---

### æ–¹æ¡ˆäºŒï¼šä½¿ç”¨WebRTCå®æ—¶éŸ³é¢‘æµ

å¦‚æœç¬¬ä¸‰æ–¹APIæ”¯æŒWebRTCï¼Œå¯ä»¥ç›´æ¥è·å–å®æ—¶éŸ³é¢‘æµï¼š

```kotlin
// WebRTCAudioDriver.kt
class WebRTCAudioDriver {
    private var peerConnection: PeerConnection? = null
    private var audioTrack: AudioTrack? = null
    private var visualizer: Visualizer? = null
    
    suspend fun setupWebRTCConnection(rtcConfig: RTCConfiguration) {
        peerConnection = PeerConnectionFactory.createPeerConnection(
            rtcConfig,
            object : PeerConnectionObserver() {
                override fun onTrack(event: RtpTransceiver?) {
                    if (event?.track is AudioTrack) {
                        val track = event.track as AudioTrack
                        setupAudioVisualizer(track)
                    }
                }
            }
        )
    }
    
    private fun setupAudioVisualizer(audioTrack: AudioTrack) {
        // åˆ›å»ºAudioTrackç”¨äºæ’­æ”¾
        this.audioTrack = createAudioTrack()
        
        // è®¾ç½®éŸ³é¢‘æ¥æ”¶å›è°ƒ
        audioTrack.setSink { audioBuffer ->
            // æ’­æ”¾éŸ³é¢‘
            audioTrack.write(audioBuffer.toByteArray(), 0, audioBuffer.size)
            
            // åˆ†æéŸ³é¢‘é©±åŠ¨Live2D
            analyzeAudioBuffer(audioBuffer)
        }
        
        // ä½¿ç”¨Visualizeråˆ†æ
        val audioSessionId = audioTrack.audioSessionId
        visualizer = Visualizer(audioSessionId).apply {
            captureSize = Visualizer.getCaptureSizeRange()[1]
            setDataCaptureListener(/* ... */)
            enabled = true
        }
    }
    
    private fun analyzeAudioBuffer(buffer: FloatArray) {
        // è®¡ç®—éŸ³é‡
        val volume = calculateRMS(buffer)
        
        // æ›´æ–°Live2D
        live2DController.updateMouthOpenness(volume)
    }
}
```

---

## ğŸ¨ Live2Då‚æ•°æ˜ å°„

### å˜´å‹å‚æ•°

```kotlin
// Live2DController.kt
class Live2DViewController {
    private var mouthOpenness = 0f
    
    fun updateMouthOpenness(value: Float) {
        mouthOpenness = value.coerceIn(0f, 1f)
        // æ›´æ–°Live2Dæ¨¡å‹å‚æ•°
        // ParamMouthOpenY: å˜´å‹å¼€æ”¾åº¦
        live2DModel.setParameterValue("ParamMouthOpenY", mouthOpenness)
    }
    
    fun updateWithAudioFeatures(volume: Float, pitch: Float) {
        // æ ¹æ®éŸ³é‡å’ŒéŸ³è°ƒè°ƒæ•´å¤šä¸ªå‚æ•°
        val mouthOpenY = volume * 0.8f
        val mouthForm = if (pitch > 300) 0.5f else -0.5f // æ ¹æ®éŸ³è°ƒè°ƒæ•´å˜´å‹
        
        live2DModel.setParameterValue("ParamMouthOpenY", mouthOpenY)
        live2DModel.setParameterValue("ParamMouthForm", mouthForm)
    }
}
```

### è¡¨æƒ…å‚æ•°

```kotlin
fun updateExpressionWithAudio(audioFeatures: AudioFeatures) {
    // æ ¹æ®éŸ³é¢‘ç‰¹å¾è°ƒæ•´è¡¨æƒ…
    val volume = audioFeatures.volume
    val pitch = audioFeatures.pitch
    
    // é«˜éŸ³é‡ -> æƒŠè®¶è¡¨æƒ…
    if (volume > 0.7f) {
        live2DModel.setParameterValue("ParamEyeLOpen", 1f)
        live2DModel.setParameterValue("ParamEyeROpen", 1f)
    }
    
    // ä½éŸ³è°ƒ -> æŸ”å’Œè¡¨æƒ…
    if (pitch < 200) {
        live2DModel.setParameterValue("ParamEyebrowLY", 0.3f)
        live2DModel.setParameterValue("ParamEyebrowRY", 0.3f)
    }
}
```

---

## ğŸ“Š å®Œæ•´æµç¨‹ç¤ºä¾‹

### åç«¯APIè¿”å›éŸ³é¢‘

```typescript
// backend-api/src/services/digital-human.service.ts
export class DigitalHumanService {
  async generateResponseWithAudio(userVoice: Buffer) {
    // 1. ASRè¯†åˆ«ï¼ˆç¬¬ä¸‰æ–¹APIï¼‰
    const text = await volcEngineASR.recognize(userVoice);
    
    // 2. LLMç”Ÿæˆå›å¤ï¼ˆæ‚¨çš„DeepSeekï¼‰
    const response = await deepSeekService.generate(text);
    
    // 3. TTSåˆæˆï¼ˆæ‚¨çš„é˜¿é‡Œäº‘TTSï¼‰
    const audioResult = await ttsService.textToSpeech({
      text: response,
    });
    
    // 4. è¿”å›éŸ³é¢‘URLå’Œæ–‡æœ¬
    return {
      audioUrl: audioResult.audioPath, // éŸ³é¢‘æ–‡ä»¶URL
      text: response,
      // å¯é€‰ï¼šä¹Ÿè¿”å›éŸ³é¢‘æµURLï¼ˆWebRTCï¼‰
      streamUrl: audioResult.streamUrl,
    };
  }
}
```

### Androidç«¯æ¥æ”¶å¹¶é©±åŠ¨Live2D

```kotlin
// DigitalInterviewScreen.ktï¼ˆå®Œæ•´ç‰ˆï¼‰
@Composable
fun DigitalInterviewScreen(
    uiState: DigitalInterviewUiState,
    onBackClick: () -> Unit
) {
    val context = LocalContext.current
    val live2DController = remember { Live2DViewController() }
    val audioDriver = remember { Live2DAudioDriver() }
    
    // å½“æ”¶åˆ°æ–°çš„éŸ³é¢‘å“åº”æ—¶
    LaunchedEffect(uiState.currentResponse) {
        uiState.currentResponse?.let { response ->
            // æ–¹å¼1ï¼šä»URLåŠ è½½éŸ³é¢‘
            response.audioUrl?.let { audioUrl ->
                audioDriver.setupAudioVisualizer(audioUrl)
            }
            
            // æ–¹å¼2ï¼šä»WebRTCæµæ¥æ”¶
            response.streamUrl?.let { streamUrl ->
                audioDriver.setupWebRTCConnection(streamUrl)
            }
        }
    }
    
    // éŸ³é¢‘é©±åŠ¨Live2Då›è°ƒ
    LaunchedEffect(Unit) {
        audioDriver.setOnMouthUpdateListener { mouthOpenness ->
            live2DController.updateMouthOpenness(mouthOpenness)
        }
    }
    
    Box(modifier = Modifier.fillMaxSize()) {
        // Live2Dæ•°å­—äººè§†å›¾
        Live2DView(
            controller = live2DController,
            modifier = Modifier
                .size(200.dp)
                .align(Alignment.TopEnd)
        )
        
        // å…¶ä»–UI...
    }
    
    DisposableEffect(Unit) {
        onDispose {
            audioDriver.release()
        }
    }
}
```

---

## âœ… æ€»ç»“

### å›ç­”æ‚¨çš„é—®é¢˜

**Q: ç¬¬ä¸‰æ–¹APIè¿”å›çš„éŸ³é¢‘èƒ½å¦ç›´æ¥é©±åŠ¨Live2Dï¼Ÿ**

**A: å¯ä»¥ï¼** ä½†éœ€è¦ï¼š

1. âœ… **æ¥æ”¶éŸ³é¢‘**ï¼šä»URLæˆ–WebRTCæµæ¥æ”¶
2. âœ… **éŸ³é¢‘è§£ç **ï¼šè½¬æ¢ä¸ºPCMæ ¼å¼
3. âœ… **å®æ—¶åˆ†æ**ï¼šä½¿ç”¨Android Visualizer APIåˆ†æéŸ³é¢‘
4. âœ… **å‚æ•°æ˜ å°„**ï¼šå°†éŸ³é¢‘ç‰¹å¾æ˜ å°„åˆ°Live2Då‚æ•°
5. âœ… **å®æ—¶æ›´æ–°**ï¼šåœ¨æ’­æ”¾éŸ³é¢‘çš„åŒæ—¶æ›´æ–°Live2DåŠ¨ç”»

### æ¨èæ–¹æ¡ˆ

1. **ä½¿ç”¨Android Visualizer API**ï¼ˆæœ€ç®€å•ï¼‰
   - ç›´æ¥è¿æ¥åˆ°MediaPlayeræˆ–AudioTrack
   - è‡ªåŠ¨æä¾›æ³¢å½¢å’ŒFFTæ•°æ®
   - æ— éœ€æ‰‹åŠ¨FFTå®ç°

2. **å®æ—¶éŸ³é¢‘æµå¤„ç†**
   - é€‚åˆWebRTCå®æ—¶æµ
   - å»¶è¿Ÿæ›´ä½
   - ä½“éªŒæ›´å¥½

3. **éŸ³é¢‘ç‰¹å¾æå–**
   - éŸ³é‡ â†’ å˜´å‹å¼€æ”¾åº¦
   - éŸ³è°ƒ â†’ è¡¨æƒ…å˜åŒ–
   - é¢‘è°± â†’ æ›´ä¸°å¯Œçš„åŠ¨ç”»

---

## ğŸ“š å‚è€ƒä»£ç 

æˆ‘å·²ç»åœ¨æ‚¨çš„é¡¹ç›®ä¸­çœ‹åˆ°æœ‰Live2Dç›¸å…³çš„ä»£ç ï¼Œå¯ä»¥åœ¨æ­¤åŸºç¡€ä¸Šé›†æˆéŸ³é¢‘é©±åŠ¨åŠŸèƒ½ã€‚

éœ€è¦æˆ‘å¸®æ‚¨ï¼š
1. å®ç°å®Œæ•´çš„éŸ³é¢‘é©±åŠ¨Live2Dä»£ç 
2. é›†æˆåˆ°æ‚¨ç°æœ‰çš„DigitalInterviewScreen
3. ä¼˜åŒ–éŸ³é¢‘åˆ†æç®—æ³•

è¯·å‘Šè¯‰æˆ‘æ‚¨çš„éœ€æ±‚ï¼

